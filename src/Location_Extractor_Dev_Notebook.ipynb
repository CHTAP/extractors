{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Parsing Files, Adding Candidates and Labels to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import json\n",
    "# Loading config\n",
    "with open(\"run_config.json\") as fl:\n",
    "    cfg = json.load(fl)\n",
    "cfg_params = cfg['parameters']\n",
    "\n",
    "# Setting snorkel path and output root\n",
    "import os\n",
    "from os.path import join\n",
    "output_root = join(cfg_params['output_path'],cfg_params['experiment_name'])\n",
    "os.environ['FONDUERDBNAME'] = cfg['postgres_db_name']\n",
    "os.environ['SNORKELDB'] = join(cfg['postgres_location'],os.environ['FONDUERDBNAME'])\n",
    "\n",
    "# For loading input files\n",
    "import pandas as pd\n",
    "\n",
    "# For running Snorkel\n",
    "from snorkel.contrib.fonduer import SnorkelSession\n",
    "from snorkel.contrib.fonduer.models import candidate_subclass\n",
    "from snorkel.contrib.fonduer import HTMLPreprocessor, OmniParser\n",
    "from utils import HTMLListPreprocessor\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "snorkeldb = create_engine(os.environ['SNORKELDB'], isolation_level=\"AUTOCOMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load labeled data from tsv\n",
    "# Creating path to labeled data\n",
    "pth_labeled = join(cfg['data_path'],'labels_and_splits')\n",
    "# Getting labele data file name\n",
    "fl_labeled = cfg['labeled_data_file']\n",
    "# Loading labeled data into dataframe\n",
    "df_labeled = pd.read_csv(join(pth_labeled,fl_labeled),sep='\\t')\n",
    "# Adding .html to filenames\n",
    "# NOTE: Need to add .html to all actual filenames before running\n",
    "path_list_labeled = [_+'.html' for _ in df_labeled['file name'].tolist()]\n",
    "\n",
    "#Load unlabeled data from tsv\n",
    "fl_unlabeled = cfg['unlabeled_data_file']\n",
    "df_unlabeled = pd.read_csv(join(pth_labeled,fl_unlabeled),sep='\\t')\n",
    "path_list_unlabeled = [_+'.html' for _ in df_unlabeled['file name'].tolist()]\n",
    "\n",
    "# Start snorkel session and creating location subclass\n",
    "session = SnorkelSession()\n",
    "Location_Extraction = candidate_subclass('location_extraction',\\\n",
    "                          [\"location\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning, empty document 018563ac-eb50-4d26-8507-31e9cf836999 passed to CoreNLPWarning, empty document 0620fe76-98ce-4add-9371-e4a752446e12 passed to CoreNLPWarning, empty document 14151fbd-febd-4602-b86d-0bf210b38963 passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 1714fcc6-d9d1-4f32-b80c-d25203bcbe2f passed to CoreNLPWarning, empty document 04c40423-3ff0-402c-9e04-b44a427e4da3 passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 0816710b-3cb4-4f63-9ed7-dad197c41b0d passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 1733019e-d9bc-4f20-93ff-a851efadf176 passed to CoreNLPWarning, empty document 03fd10d9-9b61-4771-8cfe-f2dd8c1a278b passed to CoreNLPWarning, empty document 06eec57c-ba7d-440c-910d-b73165862969 passed to CoreNLPWarning, empty document 0c7501fc-109b-4815-89f6-43d360a1d225 passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 16d41db1-b4da-4a96-90a5-8636cfe8b86c passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 05013466-0148-4daf-9842-8375bffdcaa9 passed to CoreNLPWarning, empty document 15a570dd-588f-4095-9e5b-6408198a61ae passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLPWarning, empty document 176376ce-ee90-4308-b423-105cf361307b passed to CoreNLP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 s, sys: 101 ms, total: 1.9 s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "# Getting parameter for max number of docs to load from labeled/unlabeled\n",
    "max_docs = cfg['max_docs']\n",
    "\n",
    "# Setting location for raw data\n",
    "data_loc = join(cfg['data_path'],'raw_data')\n",
    "\n",
    "# Creating a list of paths for documents from both labeled and unlabeled data\n",
    "path_list = path_list_labeled[:max_docs]+path_list_unlabeled[:max_docs]\n",
    "\n",
    "# Preprocessing documents from path_list\n",
    "doc_preprocessor = HTMLListPreprocessor(data_loc,\\\n",
    "                                file_list=path_list)\n",
    "\n",
    "# Ingest data into Fonduer via parser\n",
    "corpus_parser = OmniParser(structural=True, lingual=True, visual=False)\n",
    "%time corpus_parser.apply(doc_preprocessor, parallelism=cfg['parallel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 60\n",
      "Phrases: 36426\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.models import Document, Phrase\n",
    "\n",
    "# Checking database contents\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Phrases:\", session.query(Phrase).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Dividing into Test/Train, Extracting Features, Throttling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 30\n",
      "dev: 15\n",
      "test: 15\n",
      "[u'0726934f-a54c-402c-9d35-2dad34ef6cc0',\n",
      " u'08cd0eea-86a7-40a3-b8e7-1500c33edec5',\n",
      " u'070cd8d8-3133-4f1e-9c54-bdaeab3116da',\n",
      " u'07998afe-1494-4b87-9c20-a213b4fb29f5',\n",
      " u'03be9e25-a022-4269-9164-7033e2564304',\n",
      " u'0582d3b3-90d9-4ecb-8603-c389d952cc63',\n",
      " u'0b40c6df-dffd-45b1-87fe-8d0c7a4acbf5',\n",
      " u'06370eb0-2ad4-4f4d-b176-18d1fd07ac0a',\n",
      " u'079c559f-f8c1-4665-baec-20077dc97a0e',\n",
      " u'001a5f8b-82c5-4428-b539-0c8a0f2f87c4',\n",
      " u'0658b927-cb6b-407e-ba8f-e83d8e42e458',\n",
      " u'069da521-9287-476c-a4a5-71744fafe2bd',\n",
      " u'0ae80b59-b5e5-411e-8c90-e5e1719bf20e',\n",
      " u'0034ff21-5d7a-4edf-9150-e22c5188dde1',\n",
      " u'08e75d28-5190-46f4-b114-36076aede6dd',\n",
      " u'005dd27d-91c5-4569-b285-489391dcff4f',\n",
      " u'09702fd4-adf0-48ba-8af8-1a315f4c7489',\n",
      " u'02663026-4377-4c61-a19e-907e81e74ce0',\n",
      " u'0166a90b-5733-4336-88a0-b5a48fcb14fd',\n",
      " u'066e1a68-9f65-4a4e-a156-8cafa6f7a6d4',\n",
      " u'0aee8140-f207-4b54-9c9b-cb97fb296c5e',\n",
      " u'0189ca4e-f259-4bf3-8144-0e4fa64620e0',\n",
      " u'0656355c-45c3-47fd-a3bc-2a0a6971fc5e',\n",
      " u'06865bcb-dff9-489a-86b8-290253dfdc68',\n",
      " u'075169bb-ed46-4d76-9ddb-e85807275d21',\n",
      " u'096d252f-3bb1-410a-886a-ad211361ca7e',\n",
      " u'0a869353-ba4d-4484-8058-ec77ea6db0d3',\n",
      " u'0069a7dd-9a03-4240-9073-77744c10b467',\n",
      " u'0725a31d-512b-49f5-b727-c6c973c24e68',\n",
      " u'08da967a-30c2-4566-84d7-7c234e063603']\n",
      "[u'07a8f57c-b643-4213-b068-6a63ab4be64f',\n",
      " u'16d41db1-b4da-4a96-90a5-8636cfe8b86c',\n",
      " u'018563ac-eb50-4d26-8507-31e9cf836999',\n",
      " u'03fd10d9-9b61-4771-8cfe-f2dd8c1a278b',\n",
      " u'0d40b595-921b-4063-84f1-01a1e44be0f4',\n",
      " u'0aa75888-32c4-4914-a799-d9f21dd52535',\n",
      " u'0620fe76-98ce-4add-9371-e4a752446e12',\n",
      " u'099bfdb3-6c9d-4d2c-ba01-8cb0081048bc',\n",
      " u'14151fbd-febd-4602-b86d-0bf210b38963',\n",
      " u'0f328ecb-d4df-4d2e-ae70-0c7a4702ae1a',\n",
      " u'04c40423-3ff0-402c-9e04-b44a427e4da3',\n",
      " u'1907cfad-4039-414a-b1be-74753074bcd1',\n",
      " u'0397de89-5130-4f56-8a46-3e533d393d8d',\n",
      " u'1714fcc6-d9d1-4f32-b80c-d25203bcbe2f',\n",
      " u'176376ce-ee90-4308-b423-105cf361307b']\n",
      "[u'02ee12ba-0582-4a1f-9d54-0d59d683550f',\n",
      " u'0c7501fc-109b-4815-89f6-43d360a1d225',\n",
      " u'03a826f2-4ae7-40de-a4f9-e01bf379df9d',\n",
      " u'1294acdf-1067-44ae-b672-1302e662048a',\n",
      " u'1733019e-d9bc-4f20-93ff-a851efadf176',\n",
      " u'05013466-0148-4daf-9842-8375bffdcaa9',\n",
      " u'0a35b388-5d02-4435-b914-9f6d82521ac0',\n",
      " u'0816710b-3cb4-4f63-9ed7-dad197c41b0d',\n",
      " u'1bf37561-7447-4dd0-ad25-52b8e39c6f42',\n",
      " u'179bf6b1-db01-4b11-bfae-572d8dfb9b14',\n",
      " u'044afceb-4375-4a32-b9d6-10397259b124',\n",
      " u'16fa5506-aa8a-41bf-8318-4043eac9bfcb',\n",
      " u'06eec57c-ba7d-440c-910d-b73165862969',\n",
      " u'15a570dd-588f-4095-9e5b-6408198a61ae',\n",
      " u'0e9a0c44-602f-4ecb-9cd8-e3090709413f']\n"
     ]
    }
   ],
   "source": [
    "# Getting all documents parsed by Fonduer\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "ld   = len(docs)\n",
    "\n",
    "# Setting up train, dev, and test sets\n",
    "train_docs = set()\n",
    "dev_docs   = set()\n",
    "test_docs  = set()\n",
    "\n",
    "# Creating list of (document name, Fonduer document object) tuples\n",
    "data = [(doc.name+'.html', doc) for doc in docs]\n",
    "data.sort(key=lambda x: x[0])\n",
    "\n",
    "# Adding unlabeled data to train set, \n",
    "# labaled data to dev/test sets in alternating fashion\n",
    "for i, (doc_name, doc) in enumerate(data):\n",
    "    if doc_name in path_list_unlabeled:\n",
    "        train_docs.add(doc)\n",
    "    else:\n",
    "        if len(dev_docs)<=len(test_docs):\n",
    "            dev_docs.add(doc)\n",
    "        else:\n",
    "            test_docs.add(doc)\n",
    "\n",
    "#Printing length of train/test/dev sets\n",
    "print(\"train:\",len(train_docs))\n",
    "print(\"dev:\" ,len(dev_docs))\n",
    "print(\"test:\",len(test_docs))\n",
    "\n",
    "#Printing some filenames \n",
    "from pprint import pprint\n",
    "pprint([x.name for x in train_docs])\n",
    "pprint([x.name for x in dev_docs])\n",
    "pprint([x.name for x in test_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing matchers module and defining LocationMatcher\n",
    "from snorkel.matchers import *\n",
    "location_matcher = LocationMatcher(longest_match_only=True) \n",
    "\n",
    "#importing NGrams and defining location_ngrams \n",
    "from snorkel.contrib.fonduer.fonduer.candidates import OmniNgrams\n",
    "location_ngrams = OmniNgrams(n_max=6, split_tokens=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer.lf_helpers import *\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "# Creating filter to eliminate mentions of currency  \n",
    "def location_currencies_filter(location):\n",
    "    list_currencies = [ \"dollar\", \"dollars\", \"lira\",\"kwacha\",\"rials\",\"rial\",\"dong\",\"dongs\",\"fuerte\",\"euro\",\n",
    "                       \"euros\",\"vatu\",\"som\",\"peso\",\"sterling\",\"sterlings\",\"soms\",\"pestos\",\n",
    "                       \"pounds\", \n",
    "                  \"pound\",\"dirham\",\"dirhams\",\"hryvnia\",\"manat\",\"manats\",\"liras\",\"lira\",\n",
    "                       \"dinar\",\"dinars\",\"pa'anga\",\"franc\",\"baht\",\"schilling\",\n",
    "                  \"somoni\",\"krona\",\"lilangeni\",\"rupee\",\"rand\",\"shilling\",\"leone\",\"riyal\",\"dobra\",\n",
    "                  \"tala\",\"ruble\",\"zloty\",\"peso\",\"sol\",\"quarani\",\"kina\",\"guinean\",\"balboa\",\"krone\",\"naira\",\n",
    "                  \"cordoba\",\"kyat\",\"metical\",\"togrog\",\"leu\",\"ouguiya\",\"rufiyaa\",\"ringgit\",\"kwacha\",\n",
    "                  \"ariary\",\"denar\",\"litas\",\"loti\",\"lats\",\"kip\",\"som\",\"won\",\"tenge\",\"yen\",\"shekel\",\"rupiah\",\n",
    "                  \"forint\",\"lempira\",\"gourde\",\"quetzal\",\"cedi\",\"lari\",\"dalasi\",\"cfp\",\"birr\",\"kroon\",\"nakfa\",\n",
    "                  \"cfa\",\"Peso\",\"koruna\",\"croatian\",\"colon\",\"yuan\",\"escudo\",\"cape\",\"riel\",\"lev\",\"real\"\n",
    "                  ,\"real\",\"mark\",\"boliviano\",\"ngultrum\",\"taka\",\"manat\",\"dram\",\"kwanza\",\"lek\",\"afghani\",\"renminbi\"]\n",
    "\n",
    "    \n",
    "    cand_right_tokens = list(get_right_ngrams(location,window=2))\n",
    "    for cand in cand_right_tokens:\n",
    "        if cand not in list_currencies:\n",
    "            return location\n",
    "\n",
    "# Setting candidate filter to location_currencies_filter\n",
    "candidate_filter = location_currencies_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 29.2 ms, sys: 32.1 ms, total: 61.3 ms\n",
      "Wall time: 6.29 s\n",
      "Number of candidates: 64\n",
      "CPU times: user 6 µs, sys: 6 µs, total: 12 µs\n",
      "Wall time: 17.9 µs\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Number of candidates: 121\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Number of candidates: 96\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.candidates import CandidateExtractor\n",
    "\n",
    "# Defining candidate extractor\n",
    "candidate_extractor = CandidateExtractor(Location_Extraction,\n",
    "                                         [location_ngrams], [location_matcher],\n",
    "                                         candidate_filter=candidate_filter)\n",
    "\n",
    "# Extracting candidates from each split\n",
    "%time candidate_extractor.apply(train_docs, split=0, parallelism=cfg['parallel'])\n",
    "print(\"Number of candidates:\", session.query(Location_Extraction).filter(Location_Extraction.split == 0).count())\n",
    "%time\n",
    "for i, docs in enumerate([dev_docs, test_docs]):\n",
    "    candidate_extractor.apply(docs, split=i+1, parallelism=cfg['parallel'])\n",
    "    print(\"Number of candidates:\", session.query(Location_Extraction).filter(Location_Extraction.split == i+1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing sandbox for candiates\n",
    "from snorkel.contrib.fonduer.models import Document, Phrase\n",
    "ind = 1\n",
    "#cands = session.query(Location_Extraction).filter(Location_Extraction.split == 1).order_by(Location_Extraction).all()\n",
    "cands = session.query(Document).filter(Document.name=='05013466-0148-4daf-9842-8375bffdcaa9').all()\n",
    "# cand = cands[ind]\n",
    "# args = cand.get_contexts()\n",
    "# span = args[0]\n",
    "# c = span.sentence.is_lingual()\n",
    "# a = span.get_parent()\n",
    "# print(span)\n",
    "# print(cand[0].sentence.document.name)\n",
    "# print(cand[0].get_span())\n",
    "# print('>' in cand[0].get_parent().text)\n",
    "# print (cand[0].get_parent().text)\n",
    "# print (get_attributes(cand[0]))\n",
    "cands[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying location_extraction_feature_updates to postgres\n",
      "COPY 64\n",
      "\n",
      "CPU times: user 57.3 ms, sys: 37.7 ms, total: 95.1 ms\n",
      "Wall time: 4.84 s\n",
      "(64, 1393)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying location_extraction_feature_updates to postgres\n",
      "COPY 121\n",
      "\n",
      "CPU times: user 64.5 ms, sys: 35.6 ms, total: 100 ms\n",
      "Wall time: 4.81 s\n",
      "(121, 1393)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying location_extraction_feature_updates to postgres\n",
      "COPY 96\n",
      "\n",
      "CPU times: user 58.2 ms, sys: 39.3 ms, total: 97.6 ms\n",
      "Wall time: 5 s\n",
      "(96, 1393)\n"
     ]
    }
   ],
   "source": [
    "# Applying the featurizer (to get feature vector describing the input)\n",
    "from snorkel.contrib.fonduer import BatchFeatureAnnotator\n",
    "session.rollback()\n",
    "featurizer = BatchFeatureAnnotator(Location_Extraction)\n",
    "# Running for train set -- replace_key_set = True!\n",
    "%time F_train = featurizer.apply(split=0, replace_key_set=True, parallelism=cfg['parallel'])\n",
    "session.rollback()\n",
    "print(F_train.shape)\n",
    "# Running for dev set -- replace_key_set = False! Uses same featuers as dev set\n",
    "%time F_dev = featurizer.apply(split=1, replace_key_set=False, parallelism=cfg['parallel'])\n",
    "session.rollback()\n",
    "print(F_dev.shape)\n",
    "%time F_test = featurizer.apply(split=2, replace_key_set=False, parallelism=cfg['parallel'])\n",
    "session.rollback()\n",
    "print(F_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Adding Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from builtins import range\n",
    "import csv\n",
    "import codecs\n",
    "\n",
    "from snorkel.utils import ProgressBar\n",
    "from snorkel.models import GoldLabel, GoldLabelKey\n",
    "\n",
    "# Defining function for getting gold labels\n",
    "# Could go in utils file later!\n",
    "def load_chtap_labels(session, candidate_class, df, target, annotator_name='gold'):\n",
    "    \n",
    "    # Database nonsense to make sure that there is a \"gold\" annotator \n",
    "    ak = session.query(GoldLabelKey).filter(GoldLabelKey.name == annotator_name).first()\n",
    "    if ak is None:\n",
    "        ak = GoldLabelKey(name=annotator_name)\n",
    "        session.add(ak)\n",
    "        session.commit()   \n",
    "    \n",
    "    # Getting all candidates from dev/test set only (splits 1 and 2)\n",
    "    candidates = session.query(candidate_class).filter(candidate_class.split != 0).all()\n",
    "    cand_total = len(candidates)\n",
    "    print('Loading', cand_total, 'candidate labels')\n",
    "    pb = ProgressBar(cand_total)\n",
    "    labels=[]\n",
    "    \n",
    "    # For each candidate, add appropriate gold label\n",
    "    for i, c in enumerate(candidates):\n",
    "        pb.bar(i)\n",
    "        # Get document name for candidate\n",
    "        doc = c[0].sentence.document.name\n",
    "        # Get text span for candidate\n",
    "        val = c[0].get_span().lower()\n",
    "        # Get location label from labeled dataframe (input)\n",
    "        target_strings = df[df['file name']==doc][target].tolist()\n",
    "        # Handling location extraction\n",
    "        if target == 'location':\n",
    "                if target_strings == []:\n",
    "                    targets = ''\n",
    "                else:\n",
    "                    targets = target_strings[0].lower().split(',')\n",
    "        # Keeping this in comments...don't know what it was for\n",
    "        #context_stable_ids = '~~'.join([i.stable_id for i in c.get_contexts()])\n",
    "        label = session.query(GoldLabel).filter(GoldLabel.key == ak).filter(GoldLabel.candidate == c).first()\n",
    "        if label is None:\n",
    "            # Matching target label string to extract span, adding TRUE label if found, FALSE if not\n",
    "            # This conditional could be improved (use regex, etc.)\n",
    "            if val in targets or any([a in val for a in targets]):\n",
    "                label = GoldLabel(candidate=c, key=ak, value=1)\n",
    "            else:\n",
    "                label = GoldLabel(candidate=c, key=ak, value=-1)\n",
    "            session.add(label)\n",
    "            labels.append(label)\n",
    "    session.commit()\n",
    "    pb.close()\n",
    "\n",
    "    session.commit()\n",
    "    print(\"AnnotatorLabels created: %s\" % (len(labels),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 217 candidate labels\n",
      "[========================================] 100%\n",
      "AnnotatorLabels created: 0\n"
     ]
    }
   ],
   "source": [
    "# Adding gold labels to database\n",
    "session.rollback()\n",
    "target = 'location'\n",
    "load_chtap_labels(session, Location_Extraction, df_labeled, target ,annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Set Balance: 32.23 Percent Positive\n",
      "Test Set Balance: 37.50 Percent Positive\n"
     ]
    }
   ],
   "source": [
    "# Check class balance on dev/test\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "print('Dev Set Balance: %0.2f Percent Positive' % (100*np.sum(L_gold_dev == 1)/L_gold_dev.shape[0]))\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "print('Test Set Balance: %0.2f Percent Positive' % (100*np.sum(L_gold_test == 1)/L_gold_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Creating LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " cand_dev =session.query(Location_Extraction).filter(Location_Extraction.split == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions for true/false/abstain\n",
    "TRUE,FALSE,ABSTAIN = 1,-1,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer.lf_helpers import *\n",
    "\n",
    "# Defining LFs\n",
    "# LF API is here: http://web.stanford.edu/~lwhsiao/api/\n",
    "\n",
    "#def LF_in_breadcrumbs_1(c):\n",
    "#    parent_text = c.get_parent().text\n",
    "#    return TRUE if '>' in parent_text else ABSTAIN\n",
    "\n",
    "def LF_in_breadcrumbs_2(c):\n",
    "    attributes = list(get_attributes(c))\n",
    "    return TRUE if ('class=breadcrumbs'in attributes) or ('class=inside_scroll' in attributes) else ABSTAIN\n",
    "\n",
    "def LF_head_in_tag(c):\n",
    "    tags = list(get_ancestor_tag_names(c))\n",
    "    return FALSE if 'head' in tags else TRUE\n",
    "\n",
    "def LF_body_in_tag(c):\n",
    "    tags = list(get_ancestor_tag_names(c))\n",
    "    return TRUE if 'body' in tags else FALSE\n",
    "\n",
    "def LF_table_in_tag(c):\n",
    "    tags = list(get_ancestor_tag_names(c))\n",
    "    return TRUE if 'table' in tags else ABSTAIN\n",
    "\n",
    "#def LF_to_left(c):\n",
    "#    return TRUE if overlap(\n",
    "#      ['location','locall','outcall','stay','live','available','female escort'], \n",
    "#        get_left_ngrams(c, window=3)) else FALSE\n",
    "\n",
    "def LF_to_right(c):\n",
    "    return TRUE if overlap(\n",
    "      ['escorts','incall','outcall','stay','live','available','female escort'], \n",
    "        list(get_right_ngrams(c, window=5))) else ABSTAIN\n",
    "# Need more of these...can check tutorials for inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [] 0\n",
      "1 [u'class=inside_scroll'] 1\n",
      "2 [u'type=text/javascript'] 0\n",
      "3 [u'href=/texas/dallas/female-escorts/', u'title=Dallas, Texas Female Escort'] 0\n",
      "4 [u'class=breadcrumbs'] 1\n",
      "5 [u'href=/texas/dallas/female-escorts/', u'title=Dallas, Texas Female Escort'] 0\n",
      "6 [u'class=breadcrumbs'] 1\n",
      "7 [] 0\n",
      "8 [u'class=summary'] 0\n",
      "9 [] 0\n",
      "10 [u'class=breadcrumbs'] 1\n",
      "11 [u'class=contactmeta', u'style=margin-top:0;font-weight:normal;font-size:-10%;'] 0\n",
      "12 [u'class=inside_scroll'] 1\n",
      "13 [u'class=meta'] 0\n",
      "14 [u'class=inside_scroll'] 1\n"
     ]
    }
   ],
   "source": [
    "# API function sandbox\n",
    "from snorkel.contrib.fonduer.lf_helpers import *\n",
    "get_ancestor_tag_names(cand_dev[0])\n",
    "for i,cand in enumerate(cand_dev[:15]):\n",
    "    print (i,get_attributes(cand),LF_in_breadcrumbs_2(cand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-5b578335d891>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-5b578335d891>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    list(get_right_ngrams(c, window=5)) else 0\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Test Cell\n",
    "from snorkel.contrib.fonduer.lf_helpers import *\n",
    "import re\n",
    "# if list(get_right_ngrams(cand_dev[0], window=3, attrib='words', n_min=1, n_max=1, lower=True))==\"escorts\":\n",
    "#     print(\"hi\")\n",
    "# else:\n",
    "#     print(\"no\") \n",
    "#list(get_right_tokens(cand_dev[0], window=3))\n",
    "\n",
    "\n",
    "# def LF_to_left(c):\n",
    "#     return 1 if 'escorts' in get_right_ngrams(c, window=2) else 0\n",
    "\n",
    "# def LF_to_right(c):\n",
    "#     return 1 if overlap(\n",
    "#       ['escorts','incall','outcall','stay','live','available','female escort','female escorts','female escort'], \n",
    "#         list(get_right_ngrams(c, window=5)) else 0\n",
    "# def LF_to_left(c):\n",
    "#     return 1 if overlap(\n",
    "#       ['location','locall','outcall','stay','live','available','female escort','place','located in'], \n",
    "#         list(get_left_ngrams(c, window=2)))) else 0\n",
    "# LF_to_left(cand_dev[0])\n",
    "#LF_to_left(cand_dev[0])\n",
    "#print (cands)\n",
    "# get_attributes(cand_dev[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function LF_in_breadcrumbs_2 at 0x12e33b578>, <function LF_head_in_tag at 0x12d0980c8>, <function LF_body_in_tag at 0x12e33baa0>, <function LF_to_right at 0x12e33b320>, <function LF_table_in_tag at 0x12e33b5f0>]\n"
     ]
    }
   ],
   "source": [
    "# Collect LFs in list\n",
    "lfs_location = [#LF_in_breadcrumbs_1\n",
    "                LF_in_breadcrumbs_2,\n",
    "                LF_head_in_tag,\n",
    "                LF_body_in_tag,\n",
    "                LF_to_right,\n",
    "                #LF_to_left,\n",
    "                LF_table_in_tag,]\n",
    "print (lfs_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Running Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying location_extraction_label_updates to postgres\n",
      "COPY 64\n",
      "\n",
      "CPU times: user 29.3 ms, sys: 56.2 ms, total: 85.5 ms\n",
      "Wall time: 4.1 s\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying location_extraction_label_updates to postgres\n",
      "COPY 121\n",
      "\n",
      "CPU times: user 31.3 ms, sys: 47.3 ms, total: 78.6 ms\n",
      "Wall time: 3.99 s\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying location_extraction_label_updates to postgres\n",
      "COPY 96\n",
      "\n",
      "CPU times: user 29 ms, sys: 46.7 ms, total: 75.7 ms\n",
      "Wall time: 4.03 s\n",
      "(121, 8)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer import BatchLabelAnnotator\n",
    "\n",
    "# Annotating candidats using LFs (clear=True replaced existing)\n",
    "labeler = BatchLabelAnnotator(Location_Extraction, lfs=lfs_location)\n",
    "%time L_train = labeler.apply(split=0, clear=True, parallelism=cfg['parallel'],update_keys =True)\n",
    "%time L_dev = labeler.apply(split=1, clear=True, parallelism=cfg['parallel'],update_keys =True)\n",
    "%time L_test = labeler.apply(split=2, clear=True, parallelism=cfg['parallel'],update_keys =True)\n",
    "print(L_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.a)Computing Individual LF Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coverage_LF(lf, split, gold=None):\n",
    "    labeled = []\n",
    "    #session.query(Location_Extraction).filter(Location_Extraction.split == split\n",
    "    cands = session.query(Location_Extraction).filter(Location_Extraction.split == split).all()\n",
    "    for i,c in enumerate(cands):\n",
    "        if lf(c) != 0:\n",
    "            if gold != None and gold.size != 0:\n",
    "                labeled.append((c, gold[i,0]))\n",
    "            else:\n",
    "                labeled.append(c)\n",
    "    print (\"{} labeled candidates: {}\".format(lf.__name__, len(labeled)))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF_in_breadcrumbs_2 labeled candidates: 11\n"
     ]
    }
   ],
   "source": [
    "labeled = coverage_LF(LF_in_breadcrumbs_2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF_in_breadcrumbs_2\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            0.455\n",
      "Recall               1.0\n",
      "F1                   0.625\n",
      "----------------------------------------\n",
      "TP: 5 | FP: 6 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n",
      "LF_head_in_tag\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.872\n",
      "Neg. class accuracy: 0.659\n",
      "Precision            0.548\n",
      "Recall               0.872\n",
      "F1                   0.673\n",
      "----------------------------------------\n",
      "TP: 34 | FP: 28 | TN: 54 | FN: 5\n",
      "========================================\n",
      "\n",
      "LF_body_in_tag\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.872\n",
      "Neg. class accuracy: 0.659\n",
      "Precision            0.548\n",
      "Recall               0.872\n",
      "F1                   0.673\n",
      "----------------------------------------\n",
      "TP: 34 | FP: 28 | TN: 54 | FN: 5\n",
      "========================================\n",
      "\n",
      "LF_to_right\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            0.789\n",
      "Recall               1.0\n",
      "F1                   0.882\n",
      "----------------------------------------\n",
      "TP: 15 | FP: 4 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n",
      "LF_table_in_tag\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 4 | FP: 0 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.lf_helpers import test_LF\n",
    "for lf in lfs_location:\n",
    "    print(lf.__name__)\n",
    "    tp, fp, tn, fn = test_LF(session, lf, split=1, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location_extraction(Span(\"Texas\", sentence=129589, chars=[7,11], words=[2,2]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing a candidate from dev set\n",
    "L_dev.get_candidate(session, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.1 ms, sys: 16 µs, total: 21.1 ms\n",
      "Wall time: 21.1 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_head_in_tag</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_breadcrumbs_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_breadcrumbs_2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_body_in_tag</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_breadcrumbs</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_to_right</th>\n",
       "      <td>5</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_table_in_tag</th>\n",
       "      <td>6</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_to_left</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_head_in_tag       0  1.000000  1.000000   0.024793  34  28   5  54   \n",
       "LF_in_breadcrumbs_1  1  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_in_breadcrumbs_2  2  0.090909  0.090909   0.000000   5   6   0   0   \n",
       "LF_body_in_tag       3  1.000000  1.000000   0.024793  34  28   5  54   \n",
       "LF_in_breadcrumbs    4  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_to_right          5  0.157025  0.157025   0.024793  15   4   0   0   \n",
       "LF_table_in_tag      6  0.033058  0.033058   0.000000   4   0   0   0   \n",
       "LF_to_left           7  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "\n",
       "                     Empirical Acc.  \n",
       "LF_head_in_tag             0.727273  \n",
       "LF_in_breadcrumbs_1             NaN  \n",
       "LF_in_breadcrumbs_2        0.454545  \n",
       "LF_body_in_tag             0.727273  \n",
       "LF_in_breadcrumbs               NaN  \n",
       "LF_to_right                0.789474  \n",
       "LF_table_in_tag            1.000000  \n",
       "LF_to_left                      NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading assessing LF performance vs. gold labels\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "%time L_dev.lf_stats(L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n",
      "CPU times: user 8.32 s, sys: 42.1 ms, total: 8.36 s\n",
      "Wall time: 8.41 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "# Running the generative model\n",
    "# TODO: Add hyperparameter search \n",
    "gen_model = GenerativeModel()\n",
    "%time gen_model.train(L_train, epochs=5000, decay=0.9, step_size=0.001, reg_param=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ffa1110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing and plotting training marginals\n",
    "train_marginals = gen_model.marginals(L_train)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.45192642,  0.45071429,  0.95850357,  1.42013713,  0.44181012,\n",
       "        1.25960084,  0.45956758,  0.45825028])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing LF accuracies\n",
    "gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_head_in_tag</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.451926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_breadcrumbs_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_breadcrumbs_2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.958504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_body_in_tag</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.420137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_in_breadcrumbs</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_to_right</th>\n",
       "      <td>5</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>1.259601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_table_in_tag</th>\n",
       "      <td>6</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_to_left</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_head_in_tag       0  1.000000  1.000000   0.024793  34  28   5  54   \n",
       "LF_in_breadcrumbs_1  1  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_in_breadcrumbs_2  2  0.090909  0.090909   0.000000   5   6   0   0   \n",
       "LF_body_in_tag       3  1.000000  1.000000   0.024793  34  28   5  54   \n",
       "LF_in_breadcrumbs    4  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_to_right          5  0.157025  0.157025   0.024793  15   4   0   0   \n",
       "LF_table_in_tag      6  0.033058  0.033058   0.000000   4   0   0   0   \n",
       "LF_to_left           7  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "\n",
       "                     Empirical Acc.  Learned Acc.  \n",
       "LF_head_in_tag             0.727273      1.451926  \n",
       "LF_in_breadcrumbs_1             NaN      0.450714  \n",
       "LF_in_breadcrumbs_2        0.454545      0.958504  \n",
       "LF_body_in_tag             0.727273      1.420137  \n",
       "LF_in_breadcrumbs               NaN      0.441810  \n",
       "LF_to_right                0.789474      1.259601  \n",
       "LF_table_in_tag            1.000000      0.459568  \n",
       "LF_to_left                      NaN      0.458250  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pringint LF stats post-learning\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "prec, rec, f1 = gen_model.score(L_dev, L_gold_dev)\n",
    "L_dev.lf_stats(L_gold_dev, gen_model.weights.lf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=64  #epochs=200  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (0.06s)\tAverage loss=0.850676\n",
      "[SparseLogisticRegression] Epoch 5 (0.08s)\tAverage loss=0.740112\n",
      "[SparseLogisticRegression] Epoch 10 (0.10s)\tAverage loss=0.640737\n",
      "[SparseLogisticRegression] Epoch 15 (0.13s)\tAverage loss=0.553099\n",
      "[SparseLogisticRegression] Epoch 20 (0.15s)\tAverage loss=0.477167\n",
      "[SparseLogisticRegression] Epoch 25 (0.17s)\tAverage loss=0.412364\n",
      "[SparseLogisticRegression] Epoch 30 (0.19s)\tAverage loss=0.357701\n",
      "[SparseLogisticRegression] Epoch 35 (0.22s)\tAverage loss=0.311949\n",
      "[SparseLogisticRegression] Epoch 40 (0.24s)\tAverage loss=0.273808\n",
      "[SparseLogisticRegression] Epoch 45 (0.27s)\tAverage loss=0.242025\n",
      "[SparseLogisticRegression] Epoch 50 (0.29s)\tAverage loss=0.215479\n",
      "[SparseLogisticRegression] Epoch 55 (0.31s)\tAverage loss=0.193206\n",
      "[SparseLogisticRegression] Epoch 60 (0.33s)\tAverage loss=0.174405\n",
      "[SparseLogisticRegression] Epoch 65 (0.36s)\tAverage loss=0.158425\n",
      "[SparseLogisticRegression] Epoch 70 (0.38s)\tAverage loss=0.144743\n",
      "[SparseLogisticRegression] Epoch 75 (0.40s)\tAverage loss=0.132940\n",
      "[SparseLogisticRegression] Epoch 80 (0.42s)\tAverage loss=0.122684\n",
      "[SparseLogisticRegression] Epoch 85 (0.44s)\tAverage loss=0.113710\n",
      "[SparseLogisticRegression] Epoch 90 (0.47s)\tAverage loss=0.105807\n",
      "[SparseLogisticRegression] Epoch 95 (0.49s)\tAverage loss=0.098804\n",
      "[SparseLogisticRegression] Epoch 100 (0.52s)\tAverage loss=0.092563\n",
      "[SparseLogisticRegression] Epoch 105 (0.54s)\tAverage loss=0.086972\n",
      "[SparseLogisticRegression] Epoch 110 (0.56s)\tAverage loss=0.081941\n",
      "[SparseLogisticRegression] Epoch 115 (0.58s)\tAverage loss=0.077393\n",
      "[SparseLogisticRegression] Epoch 120 (0.61s)\tAverage loss=0.073265\n",
      "[SparseLogisticRegression] Epoch 125 (0.63s)\tAverage loss=0.069505\n",
      "[SparseLogisticRegression] Epoch 130 (0.65s)\tAverage loss=0.066067\n",
      "[SparseLogisticRegression] Epoch 135 (0.68s)\tAverage loss=0.062915\n",
      "[SparseLogisticRegression] Epoch 140 (0.70s)\tAverage loss=0.060016\n",
      "[SparseLogisticRegression] Epoch 145 (0.72s)\tAverage loss=0.057343\n",
      "[SparseLogisticRegression] Epoch 150 (0.75s)\tAverage loss=0.054872\n",
      "[SparseLogisticRegression] Epoch 155 (0.77s)\tAverage loss=0.052581\n",
      "[SparseLogisticRegression] Epoch 160 (0.79s)\tAverage loss=0.050454\n",
      "[SparseLogisticRegression] Epoch 165 (0.81s)\tAverage loss=0.048474\n",
      "[SparseLogisticRegression] Epoch 170 (0.84s)\tAverage loss=0.046627\n",
      "[SparseLogisticRegression] Epoch 175 (0.86s)\tAverage loss=0.044902\n",
      "[SparseLogisticRegression] Epoch 180 (0.88s)\tAverage loss=0.043287\n",
      "[SparseLogisticRegression] Epoch 185 (0.91s)\tAverage loss=0.041773\n",
      "[SparseLogisticRegression] Epoch 190 (0.94s)\tAverage loss=0.040351\n",
      "[SparseLogisticRegression] Epoch 195 (0.96s)\tAverage loss=0.039014\n",
      "[SparseLogisticRegression] Epoch 199 (0.99s)\tAverage loss=0.038001\n",
      "[SparseLogisticRegression] Training done (0.99s)\n",
      "CPU times: user 1.44 s, sys: 249 ms, total: 1.69 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "# Running discriminative model to predict generative model marginals from \n",
    "# features output from featurizer\n",
    "disc_model = SparseLogisticRegression()\n",
    "%time disc_model.train(F_train, train_marginals, n_epochs=200, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate discriminative on test set \n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1 -1  1 -1 -1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1\n",
      "  1  1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1  1  1 -1  1  1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Get candidates, discriminative model outputs, and discriminative model predicts\n",
    "test_candidates = [F_test.get_candidate(session, i) for i in range(F_test.shape[0])]\n",
    "test_score = disc_model.predictions(F_test)\n",
    "true_pred = [test_candidates[_] for _ in np.nditer(np.where(test_score > 0))]\n",
    "\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.5\n"
     ]
    }
   ],
   "source": [
    "#L_gold_test\n",
    "corr = test_score == L_gold_test\n",
    "acc = np.sum(corr)/len(corr)\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
