{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Parsing Files, Adding Candidates and Labels to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Loading config\n",
    "with open(\"run_config.json\") as fl:\n",
    "    cfg = json.load(fl)\n",
    "cfg_params = cfg['parameters']\n",
    "\n",
    "# Setting snorkel path and output root\n",
    "import os\n",
    "from os.path import join\n",
    "output_root = join(cfg_params['output_path'],cfg_params['experiment_name'])\n",
    "os.environ['FONDUERDBNAME'] = cfg['postgres_db_name']\n",
    "os.environ['SNORKELDB'] = join(cfg['postgres_location'],os.environ['FONDUERDBNAME'])\n",
    "\n",
    "# For loading input files\n",
    "import pandas as pd\n",
    "\n",
    "# For running Snorkel\n",
    "from snorkel.contrib.fonduer import SnorkelSession\n",
    "from snorkel.contrib.fonduer.models import candidate_subclass\n",
    "from snorkel.contrib.fonduer import HTMLPreprocessor, OmniParser\n",
    "from utils import HTMLListPreprocessor\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "snorkeldb = create_engine(os.environ['SNORKELDB'], isolation_level=\"AUTOCOMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled data from tsv\n",
    "pth_labeled = join(cfg['data_path'],'labels_and_splits')\n",
    "fl_labeled = cfg['labeled_data_file']\n",
    "df_labeled = pd.read_csv(join(pth_labeled,fl_labeled),sep='\\t')\n",
    "path_list_labeled = [_+'.html' for _ in df_labeled['file name'].tolist()]\n",
    "\n",
    "#Load unlabeled data from tsv\n",
    "fl_unlabeled = cfg['unlabeled_data_file']\n",
    "df_unlabeled = pd.read_csv(join(pth_labeled,fl_unlabeled),sep='\\t')\n",
    "path_list_unlabeled = [_+'.html' for _ in df_unlabeled['file name'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning, empty document 018563ac-eb50-4d26-8507-31e9cf836999 passed to CoreNLP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 612 ms, sys: 116 ms, total: 728 ms\n",
      "Wall time: 53.9 s\n"
     ]
    }
   ],
   "source": [
    "# Start snorkel session and creating location subclass\n",
    "session = SnorkelSession()\n",
    "Location_Extraction = candidate_subclass('location_extraction',\\\n",
    "                          [\"location\"])\n",
    "\n",
    "# Parsing documents \n",
    "max_docs = cfg['max_docs']\n",
    "data_loc = join(cfg['data_path'],'raw_data')\n",
    "path_list = path_list_labeled[:max_docs]+path_list_unlabeled[:max_docs]\n",
    "doc_preprocessor = HTMLListPreprocessor(data_loc,\\\n",
    "                                file_list=path_list)\n",
    "corpus_parser = OmniParser(structural=True, lingual=True, visual=False)\n",
    "%time corpus_parser.apply(doc_preprocessor, parallelism=cfg['parallel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Documents:', 8L)\n",
      "('Phrases:', 2388L)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.models import Document, Phrase\n",
    "\n",
    "# Checking database contents\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Phrases:\", session.query(Phrase).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing into Test/Train, Extracting Features, Throttling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4\n",
      "dev: 2\n",
      "test: 2\n",
      "[u'001a5f8b-82c5-4428-b539-0c8a0f2f87c4',\n",
      " u'005dd27d-91c5-4569-b285-489391dcff4f',\n",
      " u'0069a7dd-9a03-4240-9073-77744c10b467',\n",
      " u'0034ff21-5d7a-4edf-9150-e22c5188dde1']\n"
     ]
    }
   ],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "ld   = len(docs)\n",
    "\n",
    "train_docs = set()\n",
    "dev_docs   = set()\n",
    "test_docs  = set()\n",
    "data = [(doc.name+'.html', doc) for doc in docs]\n",
    "data.sort(key=lambda x: x[0])\n",
    "for i, (doc_name, doc) in enumerate(data):\n",
    "    if doc_name in path_list_unlabeled:\n",
    "        train_docs.add(doc)\n",
    "    else:\n",
    "        if len(dev_docs)<=len(test_docs):\n",
    "            dev_docs.add(doc)\n",
    "        else:\n",
    "            test_docs.add(doc)\n",
    "\n",
    "print \"train:\",len(train_docs)\n",
    "print \"dev:\" ,len(dev_docs)\n",
    "print \"test:\",len(test_docs)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint([x.name for x in train_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.matchers import *\n",
    "location_matcher = LocationMatcher(longest_match_only=True) \n",
    "\n",
    "from snorkel.contrib.fonduer.fonduer.candidates import OmniNgrams\n",
    "location_ngrams = OmniNgrams(n_max=6, split_tokens=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/local/0/jdunnmon/repos/anaconda3/envs/py27snorkel/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.lf_helpers import *\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "\n",
    "    \n",
    "def location_currencies_filter(location):\n",
    "    list_currencies = [ \"dollar\", \"dollars\", \"lira\",\"kwacha\",\"rials\",\"rial\",\"dong\",\"dongs\",\"fuerte\",\"euro\",\n",
    "                       \"euros\",\"vatu\",\"som\",\"peso\",\"sterling\",\"sterlings\",\"soms\",\"pestos\",\n",
    "                       \"pounds\", \n",
    "                  \"pound\",\"dirham\",\"dirhams\",\"hryvnia\",\"manat\",\"manats\",\"liras\",\"lira\",\n",
    "                       \"dinar\",\"dinars\",\"pa'anga\",\"franc\",\"baht\",\"schilling\",\n",
    "                  \"somoni\",\"krona\",\"lilangeni\",\"rupee\",\"rand\",\"shilling\",\"leone\",\"riyal\",\"dobra\",\n",
    "                  \"tala\",\"ruble\",\"zloty\",\"peso\",\"sol\",\"quarani\",\"kina\",\"guinean\",\"balboa\",\"krone\",\"naira\",\n",
    "                  \"cordoba\",\"kyat\",\"metical\",\"togrog\",\"leu\",\"ouguiya\",\"rufiyaa\",\"ringgit\",\"kwacha\",\n",
    "                  \"ariary\",\"denar\",\"litas\",\"loti\",\"lats\",\"kip\",\"som\",\"won\",\"tenge\",\"yen\",\"shekel\",\"rupiah\",\n",
    "                  \"forint\",\"lempira\",\"gourde\",\"quetzal\",\"cedi\",\"lari\",\"dalasi\",\"cfp\",\"birr\",\"kroon\",\"nakfa\",\n",
    "                  \"cfa\",\"Peso\",\"koruna\",\"croatian\",\"colon\",\"yuan\",\"escudo\",\"cape\",\"riel\",\"lev\",\"real\"\n",
    "                  ,\"real\",\"mark\",\"boliviano\",\"ngultrum\",\"taka\",\"manat\",\"dram\",\"kwanza\",\"lek\",\"afghani\",\"renminbi\"]\n",
    "\n",
    "    \n",
    "    cand_right_tokens = list(get_right_ngrams(location,window=2))\n",
    "    for cand in cand_right_tokens:\n",
    "        if cand not in list_currencies:\n",
    "            return location\n",
    "    \n",
    "candidate_filter = location_currencies_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 36 ms, sys: 268 ms, total: 304 ms\n",
      "Wall time: 4.29 s\n",
      "('Number of candidates:', 12L)\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 11 µs\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "('Number of candidates:', 26L)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "('Number of candidates:', 12L)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.candidates import CandidateExtractor\n",
    "\n",
    "candidate_extractor = CandidateExtractor(Location_Extraction,\n",
    "                                         [location_ngrams], [location_matcher],\n",
    "                                         candidate_filter=candidate_filter)\n",
    "\n",
    "%time candidate_extractor.apply(train_docs, split=0, parallelism=cfg['parallel'])\n",
    "print(\"Number of candidates:\", session.query(Location_Extraction).filter(Location_Extraction.split == i+1).count())\n",
    "%time\n",
    "for i, docs in enumerate([dev_docs, test_docs]):\n",
    "    candidate_extractor.apply(docs, split=i+1, parallelism=cfg['parallel'])\n",
    "    print(\"Number of candidates:\", session.query(Location_Extraction).filter(Location_Extraction.split == i+1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True (Span(\"Dallas\", sentence=31081, chars=[34,39], words=[8,8]),) Span(\"Dallas\", sentence=31081, chars=[34,39], words=[8,8])\n",
      "Phrase (Doc: 0397de89-5130-4f56-8a46-3e533d393d8d, Index: 50, Text: on  Friday, January 19th, 2018 in Dallas Escorts • PostID 9076788)\n"
     ]
    }
   ],
   "source": [
    "cands = session.query(Location_Extraction).filter(Location_Extraction.split == 1).order_by(Location_Extraction.id).all()\n",
    "cand = cands[0]\n",
    "args = cand.get_contexts()\n",
    "span = args[0]\n",
    "c = span.sentence.is_lingual()\n",
    "a = span.get_parent()\n",
    "print c, args, span\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'unary_tdl_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-944524e0baf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfonduer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeatureAnnotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeaturizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchFeatureAnnotator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocation_Extraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time F_train = featurizer.apply(split=0, replace_key_set=True, parallelism=1)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#%time F_dev = featurizer.apply(split=1, replace_key_set=False, parallelism=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/py27snorkel/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/py27snorkel/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/py27snorkel/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/py27snorkel/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders2/0/jdunnmon/chtap/snorkel/snorkel/contrib/fonduer/fonduer/async_annotations.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, split, key_group, replace_key_set, update_keys, update_values, storage, ignore_keys, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mremove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_file_blob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'feature'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchAnnotator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# Insert and update keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders2/0/jdunnmon/chtap/snorkel/snorkel/udf.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, xs, clear, parallelism, progress_bar, count, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running UDF...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparallelism\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mparallelism\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_st\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders2/0/jdunnmon/chtap/snorkel/snorkel/udf.pyc\u001b[0m in \u001b[0;36mapply_st\u001b[0;34m(self, xs, progress_bar, count, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Apply UDF and add results to the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;31m# Uf UDF has a reduce step, this will take care of the insert; else add to session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders2/0/jdunnmon/chtap/snorkel/snorkel/contrib/fonduer/fonduer/async_annotations.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, batch_range, table_name, split, cache, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mnonzero_kv_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manno_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_kv_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnonzero_kv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnonzero_kv_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders2/0/jdunnmon/chtap/snorkel/snorkel/contrib/fonduer/fonduer/features/features.pyc\u001b[0m in \u001b[0;36mget_all_feats\u001b[0;34m(candidates)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_content_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_structural_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_table_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders2/0/jdunnmon/chtap/snorkel/snorkel/contrib/fonduer/fonduer/features/structural_features.pyc\u001b[0m in \u001b[0;36mget_structural_feats\u001b[0;34m(candidates)\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0munary_strlib_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstable_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrlib_unary_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                         \u001b[0munary_tdl_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstable_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munary_strlib_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstable_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'unary_tdl_feats' is not defined"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer import BatchFeatureAnnotator\n",
    "featurizer = BatchFeatureAnnotator(Location_Extraction)\n",
    "%time F_train = featurizer.apply(split=0, replace_key_set=True, parallelism=1)\n",
    "print(F_train.shape)\n",
    "#%time F_dev = featurizer.apply(split=1, replace_key_set=False, parallelism=1)\n",
    "#print(F_dev.shape)\n",
    "#%time F_test = featurizer.apply(split=2, replace_key_set=False, parallelism=1)\n",
    "#print(F_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chtap_labels(session, candidate_class, df, target, annotator_name='gold'):\n",
    "    ak = session.query(GoldLabelKey).filter(GoldLabelKey.name == annotator_name).first()\n",
    "    if ak is None:\n",
    "        ak = GoldLabelKey(name=annotator_name)\n",
    "        session.add(ak)\n",
    "        session.commit()   \n",
    "        \n",
    "    candidates = session.query(candidate_class).all()\n",
    "    gold_dict = get_gold_dict(filename, attribute=attribute)\n",
    "    cand_total = len(candidates)\n",
    "    print('Loading', cand_total, 'candidate labels')\n",
    "    pb = ProgressBar(cand_total)\n",
    "    labels=[]\n",
    "    for i, c in enumerate(candidates):\n",
    "        pb.bar(i)\n",
    "        doc = c[0].sentence.document.name\n",
    "        doc_html = doc+'.html'\n",
    "        text = c[0].get_span()\n",
    "        target_string = df[df['file name']==doc_html]['meep']\n",
    "        #context_stable_ids = '~~'.join([i.stable_id for i in c.get_contexts()])\n",
    "        label = session.query(GoldLabel).filter(GoldLabel.key == ak).filter(GoldLabel.candidate == c).first()\n",
    "        if label is None:\n",
    "            if (doc, formation, measurement) in gold_dict:\n",
    "                label = GoldLabel(candidate=c, key=ak, value=1)\n",
    "            else:\n",
    "                label = GoldLabel(candidate=c, key=ak, value=-1)\n",
    "            session.add(label)\n",
    "            labels.append(label)\n",
    "    session.commit()\n",
    "    pb.close()\n",
    "\n",
    "    session.commit()\n",
    "    print(\"AnnotatorLabels created: %s\" % (len(labels),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'location'\n",
    "load_chtap_labels(session, Location_Extraction, df_labeled, target ,annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_dict(filename, doc_on=True, formation_on=True, measurement_on=True, attribute=None, docs=None, integerize=False):\n",
    "    attribute = [_.upper() for _ in attribute]\n",
    "    with codecs.open(filename, encoding=\"utf-8\") as csvfile:\n",
    "        gold_reader = csv.reader(csvfile)\n",
    "        gold_dict = set()\n",
    "        for row in gold_reader:\n",
    "            (doc, m1, formation, m2, measurement) = row\n",
    "            if docs is None or doc.upper() in docs:\n",
    "                if attribute and m2.upper() not in attribute:\n",
    "                    continue\n",
    "                else:\n",
    "                    key = []\n",
    "                    if doc_on: key.append(doc.upper())\n",
    "                    if formation_on: key.append(formation.upper())\n",
    "                    if measurement_on:\n",
    "                        if integerize:\n",
    "                            key.append(int(float(measurement)))\n",
    "                        else:\n",
    "                            key.append(measurement.upper())\n",
    "                    gold_dict.add(tuple(key))\n",
    "    return gold_dict\n",
    "\n",
    "def load_paleo_labels(session, candidate_class, filename, attribute, annotator_name='gold'):\n",
    "\n",
    "    ak = session.query(GoldLabelKey).filter(GoldLabelKey.name == annotator_name).first()\n",
    "    if ak is None:\n",
    "        ak = GoldLabelKey(name=annotator_name)\n",
    "        session.add(ak)\n",
    "        session.commit()\n",
    "\n",
    "    candidates = session.query(candidate_class).all()\n",
    "    gold_dict = get_gold_dict(filename, attribute=attribute)\n",
    "    cand_total = len(candidates)\n",
    "    print('Loading', cand_total, 'candidate labels')\n",
    "    pb = ProgressBar(cand_total)\n",
    "    labels=[]\n",
    "    for i, c in enumerate(candidates):\n",
    "        pb.bar(i)\n",
    "        doc = (c[0].sentence.document.name).upper()\n",
    "        formation = (c[0].get_span()).upper()\n",
    "        measurement = (''.join(c[1].get_span().split())).upper()\n",
    "        context_stable_ids = '~~'.join([i.stable_id for i in c.get_contexts()])\n",
    "        label = session.query(GoldLabel).filter(GoldLabel.key == ak).filter(GoldLabel.candidate == c).first()\n",
    "        if label is None:\n",
    "            if (doc, formation, measurement) in gold_dict:\n",
    "                label = GoldLabel(candidate=c, key=ak, value=1)\n",
    "            else:\n",
    "                label = GoldLabel(candidate=c, key=ak, value=-1)\n",
    "            session.add(label)\n",
    "            labels.append(label)\n",
    "    session.commit()\n",
    "    pb.close()\n",
    "\n",
    "    session.commit()\n",
    "    print(\"AnnotatorLabels created: %s\" % (len(labels),))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
