{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluate Saved Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is ensure that modules are auto-reloaded at runtime to allow for development in other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the Snorkel database location and start and connect to it.  By default, we use a PosgreSQL database backend, which can be created using `createdb DB_NAME` once psql is installed.  Note that Snorkel does *not* currently support parallel database processing with a SQLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "postgres_db_name = 'loc_jd_1M_parsed'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "#For local PostgreSQL\n",
    "#os.environ['SNORKELDB'] = 'postgres:///es_locs_small'\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('../utils')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"es_locs_small.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Setting parallelism\n",
    "parallelism = 72\n",
    "\n",
    "# Setting random seed\n",
    "seed = 1701\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallelized loader\n"
     ]
    }
   ],
   "source": [
    "from dataset_utils import set_preprocessor, combine_dedupe\n",
    "\n",
    "# Set data source: options are 'content.tsv', 'memex_jsons', 'es'\n",
    "data_source = 'es'\n",
    "\n",
    "# Setting max number of docs to ingest\n",
    "max_docs = 1000\n",
    "\n",
    "# Setting location of data source\n",
    "\n",
    "# For ES:\n",
    "#data_loc = '/lfs/local/0/jdunnmon/data/chtap/output_all_parsed'\n",
    "#data_loc = '/dfs/scratch0/jdunnmon/data/memex-data/tsvs/output_all_b'\n",
    "data_loc = '/dfs/scratch0/jdunnmon/data/memex-data/tsvs/price/test/shard/parsed'\n",
    "\n",
    "# Optional: add tsv with additional documents to create combined tsv without duplicates\n",
    "#data_loc = combine_dedupe(data_loc, 'output_location.tsv', 'combined.tsv')\n",
    "\n",
    "# If memex_raw_content is a content_field, uses term as a regex in raw data in addition to getting title and body\n",
    "term = r'\\b[Ll]ocation:|\\b[cC]ity:'\n",
    "\n",
    "# Doc length in characters, remove to have no max\n",
    "max_doc_length=10000\n",
    "\n",
    "# Setting preprocessor\n",
    "doc_preprocessor = set_preprocessor(data_source, data_loc, max_docs=max_docs, verbose=True, clean_docs=False,\n",
    "                                    content_fields=['raw_content', 'url'], term=term, max_doc_length=max_doc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(749)parse_file()\n",
      "-> num_fields = len(line.split('\\t'))\n",
      "(Pdb) n\n",
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(750)parse_file()\n",
      "-> continue\n",
      "(Pdb) num_fields\n",
      "19\n",
      "(Pdb) n\n",
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(746)parse_file()\n",
      "-> for ind, line in enumerate(tsv):\n",
      "(Pdb) n\n",
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(747)parse_file()\n",
      "-> if ind == 0:\n",
      "(Pdb) n\n",
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(751)parse_file()\n",
      "-> try:\n",
      "(Pdb) n\n",
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(754)parse_file()\n",
      "-> if num_fields == 21:\n",
      "(Pdb) n\n",
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(756)parse_file()\n",
      "-> elif num_fields == 19:\n",
      "(Pdb) n\n",
      "> /lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dataset_utils.py(757)parse_file()\n",
      "-> (memex_id, memex_content_type, crawl_data, memex_crawler, memex_doc_type, memex_extracted_metadata, memex_extracted_text, memex_extractions, memex_raw_content, memex_team, memex_timestamp, memex_type, memex_url, memex_version, domain, content_type, url, content, extractions) = line.split('\\t')\n",
      "(Pdb) len(line.split('\\t'))\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser.rule_parser import RegexTokenizer, RuleBasedParser, SpacyTokenizer\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser.simple_tokenizer import SimpleTokenizer\n",
    "from snorkel.parser.corenlp import StanfordCoreNLPServer\n",
    "\n",
    "# Applying corpus parser\n",
    "#parser = Spacy(annotators=['entity','parser'],\n",
    "#                 lang='en', num_threads=1)\n",
    "#parser = RuleBasedParser(tokenizer=SpacyTokenizer())\n",
    "parser=SimpleTokenizer(delim='<|>')\n",
    "#parser = StanfordCoreNLPServer()\n",
    "corpus_parser = CorpusParser(parser=parser)\n",
    "%time corpus_parser.apply(list(doc_preprocessor), parallelism=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 1000\n",
      "Sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "# Printing number of docs/sentences\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all documents parsed by Snorkel\n",
    "sents = session.query(Sentence).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(Document b'422CDB4BF9939B2DC198C383213B267BE146840A096F1B9510CEA24939310916',0,b'show[field_image][Alexis&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://www.naughtyreviews.com/companions/alexis-bellingham-white-female-2&quot; class=&quot;active&quot;&gt;View Image Details&lt;/a&gt;]\"\">\\\\n <img src=\"\"http://li1186-134.members.linode.com/files/imagecache/profile_gallery/images/2116/360-483-7810_bellingham_alexis_2.jpg\"\" alt=\"\"360-483-7810_bellingham_alexis.jpg\"\" title=\"\"Alexis\"\" />\\\\n </a>\\\\n </div>\\\\n <span href=\"\"#\"\" class=\"\"galRightArrow\"\"></span>\\\\n </div>\\\\n </div>\\\\n <!-- /profile-block -->\\\\n </div>\\\\n <!-- /mini-panel-elegance2_individual -->\\\\n\\\\n <div class=\"\"closure\"\">\\\\n <span class=\"\"navlinks\"\">\\\\n\\\\n </span>\\\\n </div>\\\\n </div><!--/content-->\\\\n </div><!--/panel-pane organization node profile-->\\\\n </div><!-- /tbl -->\\\\n </div><!-- /profileInfo -->\\\\n </div> <!-- /tbl -->\\\\n</div> <!-- /pageWidth -->\\\\n\\\\n\\\\n <footer>\\\\n <div class=\"\"pageWidth clearfix\"\">\\\\n \\\\t<div class=\"\"tbl\"\">\\\\n <div class=\"\"footerSplit sep\"\">\\\\n <div class=\"\"footHeader\"\">SITE links</div>\\\\n <div class=\"\"siteLinks tbl\"\">\\\\n <div>\\\\n <span>Adult Entertainment:</span>\\\\n <a href=\"\"/classified-ads/usa/wa/bellingham/\"\">Classified Ads</a><br/>\\\\n\\\\n <a href=\"\"/cams\"\">Live Web Cams</a><br/>\\\\n <a href=\"\"/videos\"\">Top Porn Reviews</a><br/>\\\\n <a href=\"\"/usa/wa/bellingham/massage-parlors\"\">Massage Parlors</a><br/>\\\\n <a href=\"\"/usa/wa/bellingham/strip-clubs\"\">Strip clubs</a> <br/>\\\\n </div>\\\\n\\\\n <div>\\\\n <span>Support/Legal:</span>\\\\n <a href=\"\"/faq/support\"\">Support</a><br/>\\\\n <a href=\"\"/faq/terms-of-use-conditions\"\">Terms of Service</a><br/>\\\\n <a href=\"\"/faq/privacy-policy\"\">Privacy Policy</a><br/>\\\\n <a href=\"\"/faq/2257\"\">2257 Exemption</a><br/>\\\\n </div>\\\\n </div>\\\\n </div>\\\\n <div class=\"\"footerSplit sep\"\">\\\\n <div class=\"\"footHeader\"\">Popular City Pages</div>\\\\n <div class=\"\"siteLinks cities tbl\"\">\\\\n <div>\\\\n <a href=\"\"/usa/ga/atlanta\"\">Atlanta</a><br/>\\\\n <a href=\"\"/usa/tx/austin\"\">Austin</a><br/>\\\\n <a href=\"\"/usa/md/baltimore\"\">Baltimore</a><br/>\\\\n <a href=\"\"/usa/ma/boston\"\">Boston</a><br/>\\\\n <a href=\"\"/usa/il/chicago\"\">Chicago</a><br/>\\\\n <a href=\"\"/usa/oh/cleveland\"\">Cleveland</a><br/>\\\\n <a href=\"\"/usa/tx/dallas\"\">Dallas</a><br/>\\\\n <a href=\"\"/usa/co/denver\"\">Denver</a><br/>\\\\n <a href=\"\"/usa/mi/detroit\"\">Detroit</a><br/>\\\\n <a href=\"\"/usa/tx/houston\"\">Houston</a><br/>\\\\n </div>\\\\n <div>\\\\n <a href=\"\"/usa/in/indianapolis\"\">Indianapolis</a><br/>\\\\n <a href=\"\"/usa/mo/kansas-city\"\">Kansas City</a><br/>\\\\n <a href=\"\"/usa/nv/las-vegas\"\">Las Vegas</a><br/>\\\\n <a href=\"\"/united-kingdom/lnd/london\"\">London</a><br/>\\\\n <a href=\"\"/usa/ca/los-angeles\"\">Los Angeles</a><br/>\\\\n <a href=\"\"/usa/fl/miami\"\">Miami</a><br/>\\\\n <a href=\"\"/usa/mn/minneapolis\"\">Minneapolis</a><br/>\\\\n <a href=\"\"/canada/qc/montreal\"\">Montreal</a><br/>\\\\n <a href=\"\"/usa/tn/nashville\"\">Nashville</a><br/>\\\\n <a href=\"\"/usa/la/new-orleans\"\">New Orleans</a><br/>\\\\n\\\\n\\\\n </div>\\\\n\\\\n <div>\\\\n <a href=\"\"/usa/ny/new-york\"\">New York</a><br/>\\\\n <a href=\"\"/usa/ca/orange-county\"\">Orange County</a><br/>\\\\n <a href=\"\"/usa/fl/orlando\"\">Orlando</a><br/>\\\\n <a href=\"\"/usa/pa/philadelphia\"\">Philadelphia</a><br/>\\\\n <a href=\"\"/usa/az/phoenix\"\">Phoenix</a><br/>\\\\n <a href=\"\"/usa/pa/pittsburgh\"\">Pittsburgh</a><br/>\\\\n <a href=\"\"/usa/ca/sacramento\"\">Sacramento</a><br/>\\\\n <a href=\"\"/usa/tx/san-antonio\"\">San Antonio</a><br/>\\\\n <a href=\"\"/usa/ca/san-diego\"\">San Diego</a><br/>\\\\n <a href=\"\"/usa/ca/san-fernando-valley\"\">San Fernando Valley</a><br/>\\\\n </div>\\\\n\\\\n <div>\\\\n <a href=\"\"/usa/ca/san-francisco\"\">San Francisco</a><br/>\\\\n <a href=\"\"/usa/wa/seattle\"\">Seattle</a><br/>\\\\n <a href=\"\"/usa/mo/st-louis\"\">St Louis</a><br/>\\\\n <a href=\"\"/usa/fl/tampa\"\">Tampa</a><br/>\\\\n <a href=\"\"/canada/on/toronto\"\">Toronto</a><br/>\\\\n <a href=\"\"/canada/bc/vancouver\"\">Vancouver</a><br/>\\\\n <a href=\"\"/usa/dc/washington-dc\"\">Washington DC</a><br/>\\\\n <a href=\"\"/city-list/companions\"\">More cities \\\\xc2\\\\xbb</a><br/>\\\\n </div>\\\\n </div>\\\\n </div>\\\\n <div class=\"\"footerSplit\"\">\\\\n <div class=\"\"footHeader\"\">Naughty Reviews - Dating with benefits</div>\\\\n <div class=\"\"footerOverview\"\">\\\\n NaughtyReviews offers a unique dating experience that allows you to have the perfect date every time. Thanks to our revolutionary 360 degree ratings system guys and girls can rate each other to keep things safe and predictable. Start to rate and get rated today to increase your member level and gain access to the most exclusive dating opportunities. NaughtyReviews makes it easy to find the hottest girls, and provides a platform so that you can incentivize them to go out with you. Girls and guys want to go out with people they know are safe and reliable. NaughtyReviews makes that possible through safety levels which are based upon a peer review system.\\\\n </div>\\\\n <div class=\"\"footHeader\"\">SOCIALIZE</div>\\\\n <div class=\"\"clearfix\"\">\\\\n <a href=\"\"http://twitter.com/NaughtyReviews/\"\" class=\"\"social twitter\"\">follow us on twitter</a>\\\\n </div>\\\\n </div>\\\\n \\\\t</div><!-- /tbl -->\\\\n\\\\n </div>\\\\n\\\\n</footer>\\\\n<div class=\"\"subFooter\"\">\\\\n <div id=\"\"rtalogo\"\">\\\\n <a href=\"\"/protectchildren\"\" title=\"\"Protect children\"\"></a>\\\\n </div>\\\\n <div class=\"\"pageWidth\"\">\\\\n &copy;2008-2017 <a href=\"\"http://www.naughtyreviews.com\"\">NaughtyReviews</a>\\\\n </div>\\\\n</div>\\\\n<script type=\"\"text/javascript\"\" src=\"\"/js/common.js\"\"></script>\\\\n<script type=\"\"text/javascript\"\">\\\\n jQuery(document).ready(function(){\\\\n jqnew.ajaxSetup({ headers: { \\\\\\'X-CSRF-TOKEN\\\\\\':\\\\\\'e9cQ61L7xxJmvcRqIyepawqUvAxwGa3YRtd2XCa6\\\\\\' } });\\\\n });\\\\n Drupal.extend({ settings: {\"\"fivestar\"\":{\"\"titleUser\"\":\"\"Your rating: \"\",\"\"titleAverage\"\":\"\"Average: \"\",\"\"feedbackSavingVote\"\":\"\"Saving your vote...\"\",\"\"feedbackVoteSaved\"\":\"\"Your vote has been saved.\"\",\"\"feedbackDeletingVote\"\":\"\"Deleting your vote...\"\",\"\"feedbackVoteDeleted\"\":\"\"Your vote has been deleted.\"\"},\"\"lightbox2\"\":{\"\"rtl\"\":false,\"\"file_path\"\":\"\"\\\\\\\\/(\\\\\\\\\\\\\\\\w\\\\\\\\\\\\\\\\w\\\\\\\\/)files\"\",\"\"base_path\"\":\"\"\\\\\\\\/\"\",\"\"default_image\"\":\"\"\\\\\\\\/sites\\\\\\\\/all\\\\\\\\/modules\\\\\\\\/lightbox2\\\\\\\\/images\\\\\\\\/brokenimage.jpg\"\",\"\"border_size\"\":10,\"\"font_color\"\":\"\"000\"\",\"\"box_color\"\":\"\"fff\"\",\"\"top_position\"\":\"\"\"\",\"\"overlay_opacity\"\":0.8,\"\"overlay_color\"\":\"\"000\"\",\"\"disable_close_click\"\":1,\"\"resize_sequence\"\":0,\"\"resize_speed\"\":400,\"\"fade_in_speed\"\":400,\"\"slide_down_speed\"\":600,\"\"use_alt_layout\"\":0,\"\"disable_resize\"\":0,\"\"disable_zoom\"\":0,\"\"force_show_nav\"\":0,\"\"loop_items\"\":0,\"\"node_link_text\"\":\"\"View Image Details\"\",\"\"node_link_target\"\":0,\"\"image_count\"\":\"\"Image !current of !total\"\",\"\"page_count\"\":\"\"Page !current of !total\"\",\"\"video_count\"\":\"\"Video !current of !total\"\",\"\"lite_press_x_close\"\":\"\"press \\\\\\\\x3ca href=\\\\\\\\\"\"#\\\\\\\\\"\" onclick=\\\\\\\\\"\"hideLightbox(); return FALSE;\\\\\\\\\"\"\\\\\\\\x3e\\\\\\\\x3ckbd\\\\\\\\x3ex\\\\\\\\x3c\\\\\\\\/kbd\\\\\\\\x3e\\\\\\\\x3c\\\\\\\\/a\\\\\\\\x3e to close\"\",\"\"enable_login\"\":false,\"\"enable_contact\"\":false,\"\"keys_close\"\":\"\"c x 27\"\",\"\"keys_previous\"\":\"\"p 37\"\",\"\"keys_next\"\":\"\"n 39\"\",\"\"keys_zoom\"\":\"\"z\"\",\"\"keys_play_pause\"\":\"\"32\"\",\"\"display_image_size\"\":\"\"original\"\",\"\"image_node_sizes\"\":\"\"()\"\",\"\"trigger_lightbox_classes\"\":\"\"\"\",\"\"trigger_lightbox_group_classes\"\":\"\"\"\",\"\"trigger_slideshow_classes\"\":\"\"\"\",\"\"trigger_lightframe_classes\"\":\"\"\"\",\"\"trigger_lightframe_group_classes\"\":\"\"\"\",\"\"custom_class_handler\"\":0,\"\"custom_trigger_classes\"\":\"\"\"\",\"\"disable_for_gallery_lists\"\":true,\"\"disable_for_acidfree_gallery_lists\"\":true,\"\"enable_acidfree_videos\"\":false,\"\"slideshow_interval\"\":5000,\"\"slideshow_automatic_start\"\":true,\"\"slideshow_automatic_exit\"\":true,\"\"show_play_pause\"\":true,\"\"pause_on_next_click\"\":false,\"\"pause_on_previous_click\"\":true,\"\"loop_slides\"\":false,\"\"iframe_width\"\":600,\"\"iframe_height\"\":400,\"\"iframe_border\"\":1,\"\"enable_video\"\":1,\"\"flvPlayer\"\":\"\"http:\\\\\\\\/\\\\\\\\/nr-eugens.naughtyreviews.com\\\\\\\\/flvplayer.swf\"\",\"\"flvFlashvars\"\":\"\"\"\"}} });\\\\n </script>\\\\n<script type=\"\"text/javascript\"\" src=\"\"/js/pu.js\"\"></script>\\\\n<script type=\"\"text/javascript\"\">\\\\n $(document).ready(function(){\\\\n $(\\\\\\'#naughtyreviews-solr-search-box-form\\\\\\').submit(function(evt){\\\\n evt.preventDefault();return false;\\\\n });\\\\n $(\\\\\\'#edit-submit\\\\\\').click(function(evt){\\\\n evt.preventDefault();window.location.href=\\\\\\'/join-tempted\\\\\\';\\\\n });\\\\n});\\\\n</script>\\\\n </body>\\\\n</html>\\\\n\\'|\" b\\'http://www.naughtyreviews.com/companions/alexis-bellingham-white-female-2\\'')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create candidate subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from dataset_utils import create_candidate_class, LocationMatcher, city_index\n",
    "from snorkel.matchers import Union, LambdaFunctionMatcher\n",
    "\n",
    "# Setting extraction type -- should be a subfield in your data source extractions field!\n",
    "extraction_type = 'location'\n",
    "\n",
    "# Creating candidate class\n",
    "candidate_class, candidate_class_name = create_candidate_class(extraction_type)\n",
    "\n",
    "# Defining ngrams for candidates\n",
    "location_ngrams = Ngrams(n_max=3)\n",
    "\n",
    "# Define matchers\n",
    "cities = city_index('../utils/data/cities15000.txt')\n",
    "geo_location_matcher = LambdaFunctionMatcher(func=cities.fast_loc)\n",
    "# spacy_location_matcher = LocationMatcher(longest_match_only=True)\n",
    "\n",
    "# Union matchers and create candidate extractor\n",
    "location_matcher = Union(geo_location_matcher)\n",
    "cand_extractor   = CandidateExtractor(candidate_class, [location_ngrams], [location_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 4min 26s, sys: 36.2 s, total: 5min 2s\n",
      "Wall time: 1h 26min 22s\n"
     ]
    }
   ],
   "source": [
    "# Applying candidate extractor to each split\n",
    "%time cand_extractor.apply(sents, split=0, parallelism=8)\n",
    "#print(\"Number of candidates:\", session.query(candidate_class).filter(candidate_class.split == 0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting candidates for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 629973 candidates...\n"
     ]
    }
   ],
   "source": [
    "# Split to pull eval candidates from\n",
    "eval_split = 0\n",
    "\n",
    "# Executing query for eval candidates\n",
    "eval_cands = session.query(candidate_class).filter(candidate_class.split == eval_split).order_by(candidate_class.id).all()\n",
    "print(f'Loaded {len(eval_cands)} candidates...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  1e-05\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.5\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] Loaded model <location_lstm>, only_param=False\n"
     ]
    }
   ],
   "source": [
    "from dm_utils import LSTM\n",
    "\n",
    "# defining model\n",
    "lstm = LSTM(n_threads=parallelism)\n",
    "\n",
    "# defining saved weights directory and name\n",
    "\n",
    "model_name = 'location_lstm' # this was provided when the model was saved!\n",
    "save_dir = 'checkpoints' # this was provided when the model was saved!\n",
    "\n",
    "# loading\n",
    "lstm.load(model_name=model_name, save_dir=save_dir, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting and plotting discriminative model marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ObjectDeletedError",
     "evalue": "Instance '<Span at 0x7f16831d3748>' has been deleted, or its row is otherwise not present.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mObjectDeletedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders5/0/jdunnmon/repos/snorkel/snorkel/learning/tensorflow/noise_aware_model.py\u001b[0m in \u001b[0;36mmarginals\u001b[0;34m(self, X, batch_size)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marginals_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dm_utils.py\u001b[0m in \u001b[0;36m_marginals_batch\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"\"\"Predict class based on user input\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mX_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dm_utils.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, candidates, extend)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;31m# Either extend word table or retrieve from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mextend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders5/0/jdunnmon/chtap/extractors/src/utils/dm_utils.py\u001b[0m in \u001b[0;36mcandidate_to_tokens\u001b[0;34m(candidate, token_type, lowercase)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcandidate_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morth_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morth_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders5/0/jdunnmon/repos/snorkel/snorkel/models/context.py\u001b[0m in \u001b[0;36mget_span\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attrib_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_span\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders5/0/jdunnmon/repos/snorkel/snorkel/models/context.py\u001b[0m in \u001b[0;36mget_attrib_span\u001b[0;34m(self, a, sep)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# NOTE: Special behavior for words currently (due to correspondence with char_offsets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'words'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_end\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attrib_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/attributes.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/attributes.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, state, dict_, passive)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mATTR_EMPTY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/strategies.py\u001b[0m in \u001b[0;36m_load_for_state\u001b[0;34m(self, state, passive)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 \u001b[0mpassive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m             )\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPASSIVE_NO_RESULT\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprimary_key_identity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/strategies.py\u001b[0m in \u001b[0;36m_get_ident_for_use_get\u001b[0;34m(self, session, state, passive)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_equated_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                 passive=passive)\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         ]\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/strategies.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_equated_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                 passive=passive)\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         ]\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/mapper.py\u001b[0m in \u001b[0;36m_get_state_attr_by_column\u001b[0;34m(self, state, dict_, column, passive)\u001b[0m\n\u001b[1;32m   2617\u001b[0m             passive=attributes.PASSIVE_RETURN_NEVER_SET):\n\u001b[1;32m   2618\u001b[0m         \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columntoproperty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_committed_state_attr_by_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/attributes.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, state, dict_, passive)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpired_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_expired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0mcallable_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/state.py\u001b[0m in \u001b[0;36m_load_expired\u001b[0;34m(self, state, passive)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmodified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeferred_scalar_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m# if the loader failed, or this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/sqlalchemy/orm/loading.py\u001b[0m in \u001b[0;36mload_scalar_attributes\u001b[0;34m(mapper, state, attribute_names)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;31m# may not complete (even if PK attributes are assigned)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_key\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0morm_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectDeletedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mObjectDeletedError\u001b[0m: Instance '<Span at 0x7f16831d3748>' has been deleted, or its row is otherwise not present."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%time eval_marginals = lstm.marginals(eval_cands)\n",
    "# Plotting eval marginals\n",
    "#plt.hist(eval_marginals, bins=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating extractions from discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gm_utils import create_extractions_dict\n",
    "\n",
    "# Enter googlemaps api key to get geocodes, leave blank to just use extracted locations\n",
    "geocode_key = None\n",
    "# geocode_key = 'AIzaSyBlLyOaasYMgMxFGUh2jJyxIG0_pZFF_jM'\n",
    "\n",
    "doc_extractions = create_extractions_dict(session, eval_cands, eval_marginals, extractions=[extraction_type],\n",
    "                                          dummy=False, geocode_key=geocode_key)\n",
    "\n",
    "# Uncomment to inspecting extractions dict to check format\n",
    "#doc_extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving extractions to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Setting filename\n",
    "out_filename = \"loc_ext_test_discriminative_eval_100K.jsonl\"\n",
    "\n",
    "# Saving file to jsonl in extractions format\n",
    "with open(out_filename, 'w') as outfile:\n",
    "    for k,v in doc_extractions.items():\n",
    "        v['id'] = k\n",
    "        print(json.dumps(v), file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Extracted String: date', ('Date', '12', 'JP', 35301, 42.46806, 140.86806)],\n",
       " ['Extracted String: goes', ('Goes', '10', 'NL', 36931, 51.50417, 3.88889)],\n",
       " ['Extracted String: name', ('Namur', 'WAL', 'BE', 106284, 50.4669, 4.86746)],\n",
       " ['Extracted String: aurora',\n",
       "  ('Aurora', 'IL', 'US', 200661, 41.76058, -88.32007),\n",
       "  ('Aurora', 'CO', 'US', 359407, 39.72943, -104.83192),\n",
       "  ('Aurora', '40', 'PH', 16178, 13.3476, 122.5195),\n",
       "  ('Aurora', 'OH', 'US', 15838, 41.31755, -81.34539)],\n",
       " ['Extracted String: new york',\n",
       "  ('New York City', 'NY', 'US', 8175133, 40.71427, -74.00597)],\n",
       " ['Extracted String: queens',\n",
       "  ('Queens', 'NY', 'US', 2272771, 40.68149, -73.83652),\n",
       "  ('Queens Village', 'NY', 'US', 51919, 40.72677, -73.74152)],\n",
       " ['Extracted String: much', ('Much', '07', 'DE', 15231, 50.90383, 7.40306)]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_extractions[\"b'3B0BD327C38D7578DA50E19F8BD68873B5C0E9CD63000BF37AEE120D7901AA06'\"]['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_extractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
