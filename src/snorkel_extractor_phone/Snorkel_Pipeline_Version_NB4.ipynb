{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluate Saved Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is ensure that modules are auto-reloaded at runtime to allow for development in other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the Snorkel database location and start and connect to it.  By default, we use a PosgreSQL database backend, which can be created using `createdb DB_NAME` once psql is installed.  Note that Snorkel does *not* currently support parallel database processing with a SQLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "postgres_db_name = 'phone_sse_ver1'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "#For local PostgreSQL\n",
    "#os.environ['SNORKELDB'] = 'postgres:///es_locs_small'\n",
    "\n",
    "# Adding utils path\n",
    "sys.path.append('../utils')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"es_locs_small.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Setting parallelism\n",
    "parallelism = 16\n",
    "\n",
    "# Setting random seed\n",
    "seed = 1701\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create candidate subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import create_candidate_class\n",
    "\n",
    "# Setting extraction type -- should be a subfield in your data source extractions field!\n",
    "extraction_type = 'phone'\n",
    "\n",
    "# Creating candidate class\n",
    "candidate_class, candidate_class_name  = create_candidate_class(extraction_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting candidates for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2135 candidates...\n"
     ]
    }
   ],
   "source": [
    "# Split to pull eval candidates from\n",
    "eval_split = 0\n",
    "\n",
    "# Executing query for eval candidates\n",
    "eval_cands = session.query(candidate_class).filter(candidate_class.split == eval_split).order_by(candidate_class.id).all()\n",
    "print(f'Loaded {len(eval_cands)} candidates...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  0.001\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.0\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] Loaded model <phone_extractor_lstm>, only_param=False\n"
     ]
    }
   ],
   "source": [
    "from dm_utils import LSTM\n",
    "\n",
    "# Exporting CUDA variable\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# defining model\n",
    "lstm = LSTM(n_threads=parallelism)\n",
    "\n",
    "# defining saved weights directory and name\n",
    "\n",
    "model_name = 'phone_extractor_lstm' # this was provided when the model was saved!\n",
    "save_dir = 'checkpoints' # this was provided when the model was saved!\n",
    "\n",
    "# loading\n",
    "lstm.load(model_name=model_name, save_dir=save_dir, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting and plotting discriminative model marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils/dm_utils.py:133: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output_word, state_word = self.word_lstm(x_emb, state_word)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_marginals = lstm.marginals(eval_cands)\n",
    "# Plotting eval marginals\n",
    "plt.hist(eval_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating extractions from discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gm_utils import create_extractions_dict\n",
    "\n",
    "# Enter googlemaps api key to get geocodes, leave blank to just use extracted locations\n",
    "geocode_key = None\n",
    "# geocode_key = 'AIzaSyBlLyOaasYMgMxFGUh2jJyxIG0_pZFF_jM'\n",
    "\n",
    "doc_extractions = create_extractions_dict(session, eval_cands, eval_marginals, extractions=[extraction_type],\n",
    "                                          dummy=False, geocode_key=geocode_key)\n",
    "\n",
    "# Uncomment to inspecting extractions dict to check format\n",
    "#doc_extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving extractions to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Setting filename\n",
    "out_filename = \"phone_ext_test_discriminative_eval.jsonl\"\n",
    "\n",
    "# Saving file to jsonl in extractions format\n",
    "with open(out_filename, 'w') as outfile:\n",
    "    for k,v in doc_extractions.items():\n",
    "        v['url'] = k\n",
    "        print(json.dumps(v), file=outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
