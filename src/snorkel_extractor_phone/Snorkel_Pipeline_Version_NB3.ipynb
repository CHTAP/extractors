{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is ensure that modules are auto-reloaded at runtime to allow for development in other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the Snorkel database location and start and connect to it.  By default, we use a PosgreSQL database backend, which can be created using `createdb DB_NAME` once psql is installed.  Note that Snorkel does *not* currently support parallel database processing with a SQLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "postgres_db_name = 'phone_sse_ver1'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "#For local PostgreSQL\n",
    "#os.environ['SNORKELDB'] = 'postgres:///es_locs_small'\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('../utils')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"es_locs_small.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Setting parallelism\n",
    "parallelism = 16\n",
    "\n",
    "# Setting random seed\n",
    "seed = 1701\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create candidate subclass and loading marginals for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import create_candidate_class\n",
    "from snorkel.annotations import load_marginals\n",
    "\n",
    "# Setting extraction type -- should be a subfield in your data source extractions field!\n",
    "extraction_type = 'phone'\n",
    "\n",
    "# Creating candidate class\n",
    "candidate_class, candidate_class_name  = create_candidate_class(extraction_type)\n",
    "\n",
    "# Loading marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting train, dev, and test candidates and gold labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "# Getting candidates\n",
    "train_cands = session.query(candidate_class).filter(candidate_class.split == 0).order_by(candidate_class.id).all()\n",
    "dev_cands   = session.query(candidate_class).filter(candidate_class.split == 1).order_by(candidate_class.id).all()\n",
    "test_cands  = session.query(candidate_class).filter(candidate_class.split == 2).order_by(candidate_class.id).all()\n",
    "\n",
    "# Getting gold labels\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and discriminative model using hyperparameter search using PyTorch LSTM end model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing lr = 1.00e-04, dropout = 0.00e+00\n",
      "============================================================\n",
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  0.0001\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.0\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] n_train= 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "../utils/dm_utils.py:328: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  return loss.data[0]\n",
      "/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([62])) that is different to the input size (torch.Size([62, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "../utils/dm_utils.py:133: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output_word, state_word = self.word_lstm(x_emb, state_word)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 5, Training error: tensor(0.6821, device='cuda:0')\tDev F1=92.69\n",
      "[LSTM] Model saved as <LSTM>, only_param=True\n",
      "[LSTM] Training done (0.24s)\n",
      "[LSTM] Loaded model <LSTM>, only_param=True\n",
      "[LSTM] F-1 Score: 0.926923076923077\n",
      "[LSTM] Model saved as <LSTM_0>, only_param=False\n",
      "[LSTM] Model saved as <LSTM_best>, only_param=False\n",
      "============================================================\n",
      "[2] Testing lr = 1.00e-06, dropout = 5.00e-01\n",
      "============================================================\n",
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  1e-06\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.5\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] n_train= 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/local/0/jdunnmon/repos/anaconda3/envs/snorkel/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 5, Training error: tensor(0.6988, device='cuda:0')\tDev F1=5.62\n",
      "[LSTM] Model saved as <LSTM>, only_param=True\n",
      "[LSTM] Training done (0.22s)\n",
      "[LSTM] Loaded model <LSTM>, only_param=True\n",
      "[LSTM] F-1 Score: 0.05622489959839357\n",
      "============================================================\n",
      "[3] Testing lr = 1.00e-04, dropout = 5.00e-01\n",
      "============================================================\n",
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  0.0001\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.5\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] n_train= 190\n",
      "[LSTM] Epoch 5, Training error: tensor(0.6843, device='cuda:0')\tDev F1=92.69\n",
      "[LSTM] Model saved as <LSTM>, only_param=True\n",
      "[LSTM] Training done (0.26s)\n",
      "[LSTM] Loaded model <LSTM>, only_param=True\n",
      "[LSTM] F-1 Score: 0.926923076923077\n",
      "============================================================\n",
      "[4] Testing lr = 1.00e-03, dropout = 0.00e+00\n",
      "============================================================\n",
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  0.001\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.0\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] n_train= 190\n",
      "[LSTM] Epoch 5, Training error: tensor(0.6249, device='cuda:0')\tDev F1=92.49\n",
      "[LSTM] Model saved as <LSTM>, only_param=True\n",
      "[LSTM] Training done (0.23s)\n",
      "[LSTM] Loaded model <LSTM>, only_param=True\n",
      "[LSTM] F-1 Score: 0.9248554913294798\n",
      "============================================================\n",
      "[5] Testing lr = 1.00e-05, dropout = 5.00e-01\n",
      "============================================================\n",
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  1e-05\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.5\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] n_train= 190\n",
      "[LSTM] Epoch 5, Training error: tensor(0.6885, device='cuda:0')\tDev F1=75.80\n",
      "[LSTM] Model saved as <LSTM>, only_param=True\n",
      "[LSTM] Training done (0.22s)\n",
      "[LSTM] Loaded model <LSTM>, only_param=True\n",
      "[LSTM] F-1 Score: 0.7579908675799086\n",
      "===============================================\n",
      "Number of learning epochs:      5\n",
      "Learning rate:                  0.0001\n",
      "Use attention:                  False\n",
      "LSTM hidden dimension:          128\n",
      "Dropout:                        0.0\n",
      "Checkpoint Patience:            2\n",
      "Batch size:                     128\n",
      "Rebalance:                      0.5\n",
      "Load pre-trained embedding:     False\n",
      "Host device:                    gpu\n",
      "Word embedding size:            300\n",
      "Word embedding:                 None\n",
      "===============================================\n",
      "[LSTM] Loaded model <LSTM_0>, only_param=False\n"
     ]
    }
   ],
   "source": [
    "from dm_utils import LSTM\n",
    "from snorkel.learning import RandomSearch\n",
    "\n",
    "# Exporting CUDA variable\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Setting param ranges to search over\n",
    "param_ranges = {\n",
    "    'lr' : [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'dropout' : [0.0, 0.5]\n",
    "}\n",
    "\n",
    "# Setting model kwargs for LSTM constructor\n",
    "model_hyperparams = {\n",
    "     'print_freq':5,\n",
    "    'dev_ckpt':True,\n",
    "    'dev_ckpt_delay':0.75,\n",
    "    'n_epochs' : 5,\n",
    "    'rebalance' : 0.5,\n",
    "    'max_sentence_length': 1000,\n",
    "    'dim': 50,\n",
    "    'host_device':'gpu',\n",
    "    'patience': 2,\n",
    "    'batch_size': 128,\n",
    "    'replace': {},\n",
    "    'lstm_hidden_dim': 128,\n",
    "    'attention': False,\n",
    "    'word_emb_path': None,\n",
    "    'word_emb_dim': 300,\n",
    "    'load_emb': False,\n",
    "    'init_pretrained': False,\n",
    "       \n",
    "}\n",
    "\n",
    "model_class_params = {}\n",
    "\n",
    "# We now add a session and probabilistic labels, as well as pass in the candidates\n",
    "# instead of the label matrix\n",
    "searcher = RandomSearch(LSTM, param_ranges, train_cands, Y_train=train_marginals, n=5,\n",
    "    model_hyperparams=model_hyperparams, model_class_params=model_class_params)\n",
    "\n",
    "# We now pass in the development candidates and the gold development labels\n",
    "lstm, run_stats = searcher.fit(dev_cands, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting discriminative model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.804, Recall: 1.000, F1 Score: 0.892\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            0.804\n",
      "Recall               1.0\n",
      "F1                   0.892\n",
      "----------------------------------------\n",
      "TP: 218 | FP: 53 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting and plotting discriminative model marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_cands = test_cands\n",
    "L_eval = L_gold_test\n",
    "eval_marginals = lstm.marginals(eval_cands)\n",
    "# Plotting eval marginals\n",
    "plt.hist(eval_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating extractions from discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gm_utils import create_extractions_dict\n",
    "\n",
    "# Enter googlemaps api key to get geocodes, leave blank to just use extracted locations\n",
    "geocode_key = None\n",
    "# geocode_key = 'AIzaSyBlLyOaasYMgMxFGUh2jJyxIG0_pZFF_jM'\n",
    "\n",
    "doc_extractions = create_extractions_dict(session, L_eval, eval_marginals, extractions=[extraction_type],\n",
    "                                          dummy=False, geocode_key=geocode_key)\n",
    "\n",
    "# Uncomment to inspecting extractions dict to check format\n",
    "#doc_extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving extractions to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Setting filename\n",
    "out_filename = \"phone_ext_test_discriminative.jsonl\"\n",
    "\n",
    "# Saving file to jsonl in extractions format\n",
    "with open(out_filename, 'w') as outfile:\n",
    "    for k,v in doc_extractions.items():\n",
    "        v['url'] = k\n",
    "        print(json.dumps(v), file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 271 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, eval_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <phone_extractor_lstm>, only_param=False\n"
     ]
    }
   ],
   "source": [
    "lstm.save(model_name='phone_extractor_lstm',save_dir='checkpoints',verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
