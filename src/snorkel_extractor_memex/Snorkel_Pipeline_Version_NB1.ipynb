{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "#postgres_db_name = 'memex_db_snorkel_large'\n",
    "#postgres_db_name = 'memex_snorkel_db_extracted_text_10K'\n",
    "#postgres_db_name = 'memex_snorkel_db_extracted_text_150K'\n",
    "postgres_db_name = 'memex_db_snorkel_tsv_1M'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('..')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"snorkel_memex.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data source: options are content.tsv, memex_jsons\n",
    "data_source = 'content.tsv'\n",
    "\n",
    "# Setting max number of docs to ingest\n",
    "max_docs = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from snorkel_utils import MemexTSVDocPreprocessor, MEMEXJsonLGZIPPreprocessor, retrieve_all_files\n",
    "\n",
    "if data_source == 'content.tsv':\n",
    "    data_loc = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/data_sample'\n",
    "    \n",
    "    # Setting path to MEMEX source data\n",
    "    file_path = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/content.tsv'\n",
    "\n",
    "    # Setting path to unique URL MEMEX source data\n",
    "    file_path_unique = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/content_unique.tsv'\n",
    "\n",
    "    # Initializing document preprocessor\n",
    "    doc_preprocessor = MemexTSVDocPreprocessor(\n",
    "        path=file_path_unique,\n",
    "        max_docs=max_docs,\n",
    "        verbose=False,\n",
    "        clean_docs=True\n",
    "    )\n",
    "\n",
    "elif data_source == 'memex_jsons':\n",
    "    # Location on raiders\n",
    "    data_loc = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/data_sample'\n",
    "\n",
    "    # Getting all file paths\n",
    "    path_list = retrieve_all_files(data_loc)\n",
    "\n",
    "    # Applying arbitrary conditions to file path list\n",
    "    path_list = [a for a in path_list if a.endswith('gz')]\n",
    "\n",
    "    # Preprocessing documents from path_list\n",
    "    # Set \"content field\" to \"extracted_text\" to use extracted text as raw content\n",
    "    doc_preprocessor = MEMEXJsonLGZIPPreprocessor(data_loc,\\\n",
    "                                    file_list=path_list,encoding='utf-8', max_docs=max_docs, verbose=False, content_field='extracted_text')\n",
    "else:\n",
    "    raise ValueError('Invalid data source!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = doc_preprocessor._read_content_file(path_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = a[a['content_type'] == 'text/html; charset=UTF-8']\n",
    "#s =a['extracted_text'][801].replace('\\n',' ').replace('\\t',' ')\n",
    "#\" \".join(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Malformatted Line!\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process CorpusParserUDF-96:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/base.py\", line 2158, in _wrap_pool_connect\n",
      "    return fn()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 403, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 791, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 532, in checkout\n",
      "    rec = pool._do_get()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 1196, in _do_get\n",
      "    self._dec_overflow()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py\", line 66, in __exit__\n",
      "    compat.reraise(exc_type, exc_value, exc_tb)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/compat.py\", line 187, in reraise\n",
      "    raise value\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 1193, in _do_get\n",
      "    return self._create_connection()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 350, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 477, in __init__\n",
      "    self.__connect(first_connect_check=True)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 674, in __connect\n",
      "    connection = pool._invoke_creator(self)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py\", line 106, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/default.py\", line 411, in connect\n",
      "    return self.dbapi.connect(*cargs, **cparams)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/psycopg2/__init__.py\", line 130, in connect\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "psycopg2.OperationalError: FATAL:  sorry, too many clients already\n",
      "FATAL:  sorry, too many clients already\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/lfs/raiders6/hdd/jdunnmon/repos/snorkel/snorkel/udf.py\", line 170, in run\n",
      "    self.session.commit()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 943, in commit\n",
      "    self.transaction.commit()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 467, in commit\n",
      "    self._prepare_impl()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 447, in _prepare_impl\n",
      "    self.session.flush()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 2254, in flush\n",
      "    self._flush(objects)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 2380, in _flush\n",
      "    transaction.rollback(_capture_exception=True)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py\", line 66, in __exit__\n",
      "    compat.reraise(exc_type, exc_value, exc_tb)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/compat.py\", line 187, in reraise\n",
      "    raise value\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 2344, in _flush\n",
      "    flush_context.execute()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py\", line 386, in execute\n",
      "    n.execute_aggregate(self, set_)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py\", line 668, in execute_aggregate\n",
      "    uow)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py\", line 156, in save_obj\n",
      "    base_mapper, states, uowtransaction\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py\", line 286, in _organize_states_for_save\n",
      "    states):\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py\", line 1252, in _connections_for_states\n",
      "    connection = uowtransaction.transaction.connection(base_mapper)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 294, in connection\n",
      "    return self._connection_for_bind(bind, execution_options)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 398, in _connection_for_bind\n",
      "    conn = self._parent._connection_for_bind(bind, execution_options)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/orm/session.py\", line 409, in _connection_for_bind\n",
      "    conn = bind.contextual_connect()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/base.py\", line 2123, in contextual_connect\n",
      "    self._wrap_pool_connect(self.pool.connect, None),\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/base.py\", line 2162, in _wrap_pool_connect\n",
      "    e, dialect, self)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/base.py\", line 1476, in _handle_dbapi_exception_noconnection\n",
      "    exc_info\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/compat.py\", line 203, in raise_from_cause\n",
      "    reraise(type(exception), exception, tb=exc_tb, cause=cause)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/compat.py\", line 186, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/base.py\", line 2158, in _wrap_pool_connect\n",
      "    return fn()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 403, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 791, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 532, in checkout\n",
      "    rec = pool._do_get()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 1196, in _do_get\n",
      "    self._dec_overflow()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py\", line 66, in __exit__\n",
      "    compat.reraise(exc_type, exc_value, exc_tb)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/util/compat.py\", line 187, in reraise\n",
      "    raise value\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 1193, in _do_get\n",
      "    return self._create_connection()\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 350, in _create_connection\n",
      "    return _ConnectionRecord(self)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 477, in __init__\n",
      "    self.__connect(first_connect_check=True)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/pool.py\", line 674, in __connect\n",
      "    connection = pool._invoke_creator(self)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py\", line 106, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/sqlalchemy/engine/default.py\", line 411, in connect\n",
      "    return self.dbapi.connect(*cargs, **cparams)\n",
      "  File \"/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/psycopg2/__init__.py\", line 130, in connect\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already\n",
      "FATAL:  sorry, too many clients already\n",
      " (Background on this error at: http://sqlalche.me/e/e3q8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 42s, sys: 58.4 s, total: 5min 41s\n",
      "Wall time: 53min 58s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "\n",
    "# Applying corpus parser\n",
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "%time corpus_parser.apply(list(doc_preprocessor), parallelism=96, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 1000000\n",
      "Sentences: 9086034\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "# Printing number of docs/sentences\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Importing gold label dict\n",
    "with open('/lfs/local/0/jdunnmon/data/memex-data/gold_labels/gold_loc.pickle', 'rb') as handle:\n",
    "    gold_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 980000 Docs, 8888804 Sentences\n",
      "Dev: 4333 Docs, 47327 Sentences\n",
      "Test: 4334 Docs, 47303 Sentences\n",
      "CPU times: user 33min 47s, sys: 3min 19s, total: 37min 7s\n",
      "Wall time: 52min 43s\n"
     ]
    }
   ],
   "source": [
    "from snorkel_utils import create_test_train_splits\n",
    "\n",
    "# Getting all documents parsed by Snorkel\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "# Creating train, test, dev splits\n",
    "%time train_docs, dev_docs, test_docs, train_sents, dev_sents, test_sents = create_test_train_splits(docs, 'location', gold_dict=gold_dict, dev_frac=0.01, test_frac=0.01,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "\n",
    "# Designing candidate subclasses\n",
    "LocationExtraction = candidate_subclass('Location', ['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "#from snorkel.matchers import LocationMatcher\n",
    "from snorkel_utils import get_location_matcher, get_candidate_filter, CandidateExtractorFilter, LocationMatcher\n",
    "\n",
    "# Defining ngrams and matcher for candidate extractor\n",
    "location_ngrams   = Ngrams(n_max=3)\n",
    "#location_matcher  = get_location_matcher()\n",
    "location_matcher = LocationMatcher(longest_match_only=True)\n",
    "#candidate_filter =  get_candidate_filter()\n",
    "#cand_extractor = CandidateExtractorFilter(LocationExtraction,[location_ngrams],[location_matcher],candidate_filter=candidate_filter)\n",
    "cand_extractor    = CandidateExtractor(LocationExtraction, [location_ngrams], [location_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 19min 44s, sys: 2min 42s, total: 22min 26s\n",
      "Wall time: 25min 12s\n",
      "Number of candidates: 380402\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 8.33 s, sys: 17.1 s, total: 25.5 s\n",
      "Wall time: 32.6 s\n",
      "Number of candidates: 2307\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 7.07 s, sys: 13.6 s, total: 20.7 s\n",
      "Wall time: 27.5 s\n",
      "Number of candidates: 2431\n"
     ]
    }
   ],
   "source": [
    "for k, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    %time cand_extractor.apply(sents, split=k, parallelism=8)\n",
    "    print(\"Number of candidates:\", session.query(LocationExtraction).filter(LocationExtraction.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2307 candidate labels\n",
      "[========================================] 100%\n",
      "\n",
      "AnnotatorLabels created: 2307\n",
      "CPU times: user 4min 47s, sys: 52.4 s, total: 5min 39s\n",
      "Wall time: 5min 45s\n",
      "Loading 2431 candidate labels\n",
      "[========================================] 100%\n",
      "\n",
      "AnnotatorLabels created: 2431\n",
      "CPU times: user 1min 22s, sys: 6.78 s, total: 1min 29s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "from snorkel_utils import get_gold_labels_from_meta\n",
    "\n",
    "# Adding dev gold labels using dictionary\n",
    "%time missed_dev = get_gold_labels_from_meta(session, LocationExtraction, 'location', 1, annotator='gold', gold_dict=gold_dict)\n",
    "\n",
    "# Adding test gold labels using dictionary\n",
    "%time missed_test = get_gold_labels_from_meta(session, LocationExtraction, 'location', 2, annotator='gold', gold_dict=gold_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel_utils import remove_gold_labels\n",
    "# Remove gold labels if you want -- uncomment!\n",
    "#remove_gold_labels(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Positive: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Checking percent of gold labels that are positive\n",
    "from snorkel_utils import check_gold_perc\n",
    "perc_pos = check_gold_perc(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX (area for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_docs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,0,b'\"Fargo.'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,1,b'920-850-6302'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,2,b\"I'm back\"),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,3,b'and I need to finish what I started,'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,4,b'clean comfortable incalls'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,5,b\"I'm hot sexy and ready for you.\"),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,6,b\"5'5 brown eyes and a body to die for\"),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,7,b\"I'm looking to get spoiled.\"),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,8,b'Read reviews on T3R'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,9,b\"if my legitimate pictures don't convince you go the extra mile, and bring me flowers or a flower and recieve a hot sexy picture with/of me HH/H specials Kali Sunshine\"),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,10,b'920-850-6302'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,11,b'No AA No blocked calls INCALL ONLY.'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,12,b'\\\\\\\\n<a href=\\\\\\\\/more.php?article=108&amp;p=1\\\\\\\\\"\"'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,13,b'>'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,14,b'We are on Adult Finder</a'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,15,b'> soooo you can find us all on there if you want... sticky_dolce\\\\\\\\n<br>\\\\\\\\n'),\n",
       " Sentence(Document http://920-850-6302.escortphonelist.com/im-here-i-hope-your-near-3225785.html,16,b'<br>\"\"\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(Document http://liveescortreviews.com/ad/sanjose/408-621-7949/1/199206,1,b'Ph@t @$$')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
