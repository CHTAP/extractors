{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "#postgres_db_name = 'memex_db_snorkel_large'\n",
    "#postgres_db_name = 'memex_snorkel_db_extracted_text_10K'\n",
    "#postgres_db_name = 'memex_snorkel_db_extracted_text_150K'\n",
    "#postgres_db_name = 'memex_db_snorkel_tsv_1M'\n",
    "postgres_db_name = 'es_locs_small'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('..')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"snorkel_memex.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data source: options are content.tsv, memex_jsons\n",
    "data_source = 'es'\n",
    "\n",
    "# Setting max number of docs to ingest\n",
    "max_docs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/local/0/jdunnmon/repos/anaconda3/envs/py36torch/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from snorkel_utils import MemexTSVDocPreprocessor, MEMEXJsonLGZIPPreprocessor, ESTSVDocPreprocessor, retrieve_all_files\n",
    "\n",
    "if data_source == 'content.tsv':\n",
    "    data_loc = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/data_sample'\n",
    "    \n",
    "    # Setting path to MEMEX source data\n",
    "    file_path = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/content.tsv'\n",
    "\n",
    "    # Setting path to unique URL MEMEX source data\n",
    "    file_path_unique = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/content_unique.tsv'\n",
    " \n",
    "\n",
    "    # Initializing document preprocessor\n",
    "    doc_preprocessor = MemexTSVDocPreprocessor(\n",
    "        path=file_path_unique,\n",
    "        max_docs=max_docs,\n",
    "        verbose=False,\n",
    "        clean_docs=True\n",
    "    )\n",
    "    \n",
    "elif data_source == 'es':\n",
    "    # Setting path to MEMEX source data\n",
    "    #file_path_unique = '/dfs/scratch1/jdunnmon/data/memex-data/es/es_locations.tsv'\n",
    "    file_path_unique = '/lfs/local/0/jdunnmon/chtap/extractors/src/elasticsearch_preprocessing/output_location.tsv'\n",
    "    \n",
    "        # Initializing document preprocessor\n",
    "    doc_preprocessor = ESTSVDocPreprocessor(\n",
    "        path=file_path_unique,\n",
    "        max_docs=max_docs,\n",
    "        verbose=False,\n",
    "        clean_docs=True\n",
    "    )\n",
    "\n",
    "elif data_source == 'memex_jsons':\n",
    "    # Location on raiders\n",
    "    data_loc = '/lfs/local/0/jdunnmon/data/memex-data/gold_labels/data_sample'\n",
    "\n",
    "    # Getting all file paths\n",
    "    path_list = retrieve_all_files(data_loc)\n",
    "\n",
    "    # Applying arbitrary conditions to file path list\n",
    "    path_list = [a for a in path_list if a.endswith('gz')]\n",
    "\n",
    "    # Preprocessing documents from path_list\n",
    "    # Set \"content field\" to \"extracted_text\" to use extracted text as raw content\n",
    "    doc_preprocessor = MEMEXJsonLGZIPPreprocessor(data_loc,\\\n",
    "                                    file_list=path_list,encoding='utf-8', max_docs=max_docs, verbose=False, content_field='extracted_text')\n",
    "else:\n",
    "    raise ValueError('Invalid data source!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = doc_preprocessor._read_content_file(path_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = a[a['content_type'] == 'text/html; charset=UTF-8']\n",
    "#s =a['extracted_text'][801].replace('\\n',' ').replace('\\t',' ')\n",
    "#\" \".join(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 22.5 s, sys: 1.18 s, total: 23.6 s\n",
      "Wall time: 10min\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "\n",
    "# Applying corpus parser\n",
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "%time corpus_parser.apply(list(doc_preprocessor), parallelism=8, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 7508\n",
      "Sentences: 104986\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "# Printing number of docs/sentences\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Importing gold label dict\n",
    "with open('/lfs/local/0/jdunnmon/data/memex-data/gold_labels/gold_loc.pickle', 'rb') as handle:\n",
    "    gold_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malformatted JSON Entry!\n",
      "Malformatted JSON Entry!\n",
      "Malformatted JSON Entry!\n",
      "Malformatted JSON Entry!\n",
      "Malformatted JSON Entry!\n",
      "Malformatted JSON Entry!\n",
      "Malformatted JSON Entry!\n",
      "Train: 7358 Docs, 102888 Sentences\n",
      "Dev: 75 Docs, 976 Sentences\n",
      "Test: 75 Docs, 1122 Sentences\n",
      "CPU times: user 18.1 s, sys: 1.08 s, total: 19.2 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel_utils import create_test_train_splits\n",
    "\n",
    "# Getting all documents parsed by Snorkel\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "# Creating train, test, dev splits\n",
    "%time train_docs, dev_docs, test_docs, train_sents, dev_sents, test_sents = create_test_train_splits(docs, 'location', gold_dict=None, dev_frac=0.01, test_frac=0.01,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "# Designing candidate subclasses\n",
    "LocationExtraction = candidate_subclass('Location', ['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "#from snorkel.matchers import LocationMatcher\n",
    "from snorkel_utils import get_location_matcher, get_candidate_filter, CandidateExtractorFilter, LocationMatcher\n",
    "\n",
    "# Defining ngrams and matcher for candidate extractor\n",
    "location_ngrams   = Ngrams(n_max=3)\n",
    "#location_matcher  = get_location_matcher()\n",
    "location_matcher = LocationMatcher(longest_match_only=True)\n",
    "#candidate_filter =  get_candidate_filter()\n",
    "#cand_extractor = CandidateExtractorFilter(LocationExtraction,[location_ngrams],[location_matcher],candidate_filter=candidate_filter)\n",
    "cand_extractor    = CandidateExtractor(LocationExtraction, [location_ngrams], [location_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 13.4 s, sys: 1.5 s, total: 14.9 s\n",
      "Wall time: 20.4 s\n",
      "Number of candidates: 7202\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 164 ms, sys: 232 ms, total: 396 ms\n",
      "Wall time: 3.49 s\n",
      "Number of candidates: 53\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 208 ms, sys: 248 ms, total: 456 ms\n",
      "Wall time: 3.55 s\n",
      "Number of candidates: 93\n"
     ]
    }
   ],
   "source": [
    "for k, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    %time cand_extractor.apply(sents, split=k, parallelism=8)\n",
    "    print(\"Number of candidates:\", session.query(LocationExtraction).filter(LocationExtraction.split == k).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 53 candidate labels\n",
      "[========================================] 100%\n",
      "\n",
      "AnnotatorLabels created: 53\n",
      "CPU times: user 2.01 s, sys: 152 ms, total: 2.16 s\n",
      "Wall time: 2.19 s\n",
      "Loading 93 candidate labels\n",
      "[========================================] 100%\n",
      "\n",
      "AnnotatorLabels created: 93\n",
      "CPU times: user 1.8 s, sys: 92 ms, total: 1.89 s\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel_utils import get_gold_labels_from_meta\n",
    "\n",
    "# Adding dev gold labels using dictionary\n",
    "%time missed_dev = get_gold_labels_from_meta(session, LocationExtraction, 'location', 1, annotator='gold', gold_dict=None)\n",
    "\n",
    "# Adding test gold labels using dictionary\n",
    "%time missed_test = get_gold_labels_from_meta(session, LocationExtraction, 'location', 2, annotator='gold', gold_dict=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel_utils import remove_gold_labels\n",
    "# Remove gold labels if you want -- uncomment!\n",
    "#remove_gold_labels(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Positive: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Checking percent of gold labels that are positive\n",
    "from snorkel_utils import check_gold_perc\n",
    "perc_pos = check_gold_perc(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX (area for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_docs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',0,b'b\\'\"Sou uma mulher encantadora, culta, meiga, carinhosa, bom nvel, boa conversa, experiente.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',1,b'Convivo com homens de'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',2,b'bom gosto'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',3,b'e que gostem de estar'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',4,b'em boa companhia ao lado de uma mulher bonita, bem cuidada, charmosa, sensual e sem preconceitos.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',5,b'Tenho um corpo bonito e bem cuidado, seios durinhos, bumbum grande, pele cheirosa e macia, cabelos castanhos.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',6,b'Aprecio senhores meigos educados e simpticos.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',7,b'Realizo fantasias, simulao masculina e fetiches.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',8,b'Adoro uma boa lngua, tenho'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',9,b'um grelinho grande.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',10,b'Se quiseres conhecer-me s ligar, atendo 24 horas com marcaes.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',11,b'No respondo e-mails e sms.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',12,b'Speak english, parle franais.'),\n",
       " Sentence(Document b'44FB22984AAED962B4E98E08E1A2861D58E1127760A2F4017593BABE75F0238D',13,b'Tm: 961.418.784\"\\'')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(Document http://liveescortreviews.com/ad/sanjose/408-621-7949/1/199206,1,b'Ph@t @$$')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ethnicity\": \"rican\", \"location\": \"Df, Mexico\", \"title\": \"Katya, flaquita sexy, real y cogelona. Df, 5522139760 - Df anuncios clasificados de escorts, modelos, edecanes, acompaantes - escorts - backpage.mx\"}\n"
     ]
    }
   ],
   "source": [
    "doc = docs[5]\n",
    "dict_string = doc.meta['extractions'].replace('\\\\n','').replace('\\'','\"').replace('|','').strip('\\n').strip('\\r').strip('b').strip('\"').replace('\"\"','\"').replace('\\\\\"',\"\\\\\").replace('\\\\','\\\\\\\\')\n",
    "dict_string = \" \".join(dict_string.split()).replace('\" \"','')\n",
    "#dict_string = dict_string[1:-1]\n",
    "print(dict_string)\n",
    "import json\n",
    "a = json.loads(str(dict_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = doc.meta['extractions'].replace('\\\\n','').strip('\\n').strip('b').strip('\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = json.loads(a).replace(\"'\",'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"age\": \"29\", \"location\": \"Pretoria, South Africa\", \"post_date\": \"2015-11-28\", \"title\": \"Kinky Martin - Sophisticated, Naughty, Well Hung African Hunk \"          \"Playmate for Women - Pretoria male escorts - backpage.com\"}'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"{\\'location\\': \\'Df, Mexico\\',\\\\n \\'title\\': \\'ALEXXANDRA  Nena Super Coqueta y Atractiva !! Rico ORAL Natural y \\'\\\\n          \\'Polaco.. - Df anuncios clasificados erticos y para adultos - \\'\\\\n          \\'erticos - backpage.mx\\'}\"\\r\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.meta['extractions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"{\\'age\\'',\n",
       " \" '29',\\\\n 'location'\",\n",
       " \" 'Pretoria, South Africa',\\\\n 'post_date'\",\n",
       " \" '2015-11-28',\\\\n 'title'\",\n",
       " ' \\'Kinky Martin - Sophisticated, Naughty, Well Hung African Hunk \\'\\\\n          \\'Playmate for Women - Pretoria male escorts - backpage.com\\'}\"']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.meta['extractions'].strip('b').strip('\\n').strip('\\r').split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Brussel, Belgium',\n",
       " 'title': 'Zoe infirmiere - Brussel escortes - backpage.com'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"location\": \"Brussel, Belgium\", \"title\": \"Zoe infirmiere - Brussel escortes - backpage.com\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"Guadalajara, Mexico\", \"phone\": \"(331) 768-3420\", \"title\": \"riquisimo servio escort de primer nivel - Guadalajara anuncios clasificados de escorts, modelos, edecanes, acompaantes - escorts - backpage.mx\"}'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(dict_string.split()).replace('\" \"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
