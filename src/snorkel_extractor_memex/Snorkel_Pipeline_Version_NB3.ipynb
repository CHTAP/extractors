{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is ensure that modules are auto-reloaded at runtime to allow for development in other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the Snorkel database location and start and connect to it.  By default, we use a PosgreSQL database backend, which can be created using `createdb DB_NAME` once psql is installed.  Note that Snorkel does *not* currently support parallel database processing with a SQLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "\n",
    "postgres_db_name = 'es_locs_small'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('..')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"es_locs_small.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Setting parallelism\n",
    "parallelism = 32\n",
    "\n",
    "# Setting random seed\n",
    "seed = 1701\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create candidate subclass and loading marginals for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import create_candidate_class\n",
    "from snorkel.annotations import load_marginals\n",
    "\n",
    "# Setting extraction type -- should be a subfield in your data source extractions field!\n",
    "extraction_type = 'location'\n",
    "\n",
    "# Creating candidate class\n",
    "candidate_class, candidate_class_name  = create_candidate_class(extraction_type)\n",
    "\n",
    "# Loading marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting train, dev, and test candidates and gold labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "# Getting candidates\n",
    "train_cands = session.query(LocationExtraction).filter(LocationExtraction.split == 0).order_by(candidate_class.id).all()\n",
    "dev_cands   = session.query(LocationExtraction).filter(LocationExtraction.split == 1).order_by(candidate_class.id).all()\n",
    "test_cands  = session.query(LocationExtraction).filter(LocationExtraction.split == 2).order_by(candidate_class.id).all()\n",
    "\n",
    "# Getting gold labels\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and discriminative model using hyperparameter search using PyTorch LSTM end model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=1708  #epochs=2  batch size=64\n",
      "[LSTM] Epoch 1 (52.87s)\tAverage loss=0.507729\tDev F1=50.00\n",
      "[LSTM] Epoch 2 (101.10s)\tAverage loss=0.403025\tDev F1=46.15\n",
      "[LSTM] Training done (101.17s)\n"
     ]
    }
   ],
   "source": [
    "from dm_utils import LSTM\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        50,\n",
    "    'n_epochs':   2,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1,\n",
    "    'max_sentence_length': 100\n",
    "}\n",
    "\n",
    "# Defining end model\n",
    "# TODO: check for cuda and use GPU\n",
    "lstm = LSTM(n_threads=parallelism)\n",
    "\n",
    "# Training end model\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting discriminative model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.357, Recall: 1.000, F1 Score: 0.526\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.526\n",
      "Precision            0.357\n",
      "Recall               1.0\n",
      "F1                   0.526\n",
      "----------------------------------------\n",
      "TP: 5 | FP: 9 | TN: 10 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting and plotting discriminative model marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_cands = test_cands\n",
    "eval_marginals = lstm.marginals(eval_cands)\n",
    "# Plotting eval marginals\n",
    "plt.hist(eval_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating extractionsf from discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gm_utils import create_extractions_dict\n",
    "doc_extractions = create_extractions_dict(session, eval_cands, eval_marginals, extractions=[extraction_type], dummy=True)\n",
    "\n",
    "# Uncomment to inspecting extractions dict to check format\n",
    "#doc_extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving extractions to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Setting filename\n",
    "out_filename = \"loc_ext_test_discriminative.jsonl\"\n",
    "\n",
    "# Saving file to jsonl in extractions format\n",
    "with open(out_filename, 'w') as outfile:\n",
    "    for k,v in doc_extractions.items():\n",
    "        v['url'] = k\n",
    "        print(json.dumps(v), file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 24 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, eval_cands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
