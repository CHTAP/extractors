{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is ensure that modules are auto-reloaded at runtime to allow for development in other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the Snorkel database location and start and connect to it.  By default, we use a PosgreSQL database backend, which can be created using `createdb DB_NAME` once psql is installed.  Note that Snorkel does *not* currently support parallel database processing with a SQLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "postgres_db_name = 'es_locs_small'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "#For local PostgreSQL\n",
    "#os.environ['SNORKELDB'] = 'postgres:///es_locs_small'\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('..')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"es_locs_small.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Setting parallelism\n",
    "parallelism = 32\n",
    "\n",
    "# Setting random seed\n",
    "seed = 1701\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create candidate subclass and loading marginals for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import create_candidate_class\n",
    "from snorkel.annotations import load_marginals\n",
    "\n",
    "# Setting extraction type -- should be a subfield in your data source extractions field!\n",
    "extraction_type = 'location'\n",
    "\n",
    "# Creating candidate class\n",
    "candidate_class, candidate_class_name  = create_candidate_class(extraction_type)\n",
    "\n",
    "# Loading marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting train, dev, and test candidates and gold labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "# Getting candidates\n",
    "train_cands = session.query(candidate_class).filter(candidate_class.split == 0).order_by(candidate_class.id).all()\n",
    "dev_cands   = session.query(candidate_class).filter(candidate_class.split == 1).order_by(candidate_class.id).all()\n",
    "test_cands  = session.query(candidate_class).filter(candidate_class.split == 2).order_by(candidate_class.id).all()\n",
    "\n",
    "# Getting gold labels\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and discriminative model using hyperparameter search using PyTorch LSTM end model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing lr = 1.00e-04, dropout = 0.00e+00\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1408  #epochs=5  batch size=64\n",
      "[LSTM] Epoch 1 (15.22s)\tAverage loss=0.688803\tDev F1=23.02\n",
      "[LSTM] Epoch 5 (67.59s)\tAverage loss=0.645820\tDev F1=73.13\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (67.99s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.7313432835820897\n",
      "[LSTM] Model saved as <LSTM_0>\n",
      "[LSTM] Model saved as <LSTM_best>\n",
      "============================================================\n",
      "[2] Testing lr = 1.00e-06, dropout = 5.00e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1408  #epochs=5  batch size=64\n",
      "[LSTM] Epoch 1 (16.02s)\tAverage loss=0.696080\tDev F1=26.52\n",
      "[LSTM] Epoch 5 (68.14s)\tAverage loss=0.694084\tDev F1=26.52\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (68.53s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.2651933701657459\n",
      "============================================================\n",
      "[3] Testing lr = 1.00e-04, dropout = 5.00e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1408  #epochs=5  batch size=64\n",
      "[LSTM] Epoch 1 (14.71s)\tAverage loss=0.690950\tDev F1=22.86\n",
      "[LSTM] Epoch 5 (69.86s)\tAverage loss=0.650769\tDev F1=73.13\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (70.25s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.7313432835820897\n",
      "============================================================\n",
      "[4] Testing lr = 1.00e-03, dropout = 0.00e+00\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1408  #epochs=5  batch size=64\n",
      "[LSTM] Epoch 1 (16.61s)\tAverage loss=0.649432\tDev F1=74.24\n",
      "[LSTM] Epoch 5 (72.31s)\tAverage loss=0.500934\tDev F1=77.37\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (72.71s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.7737226277372262\n",
      "[LSTM] Model saved as <LSTM_3>\n",
      "[LSTM] Model saved as <LSTM_best>\n",
      "============================================================\n",
      "[5] Testing lr = 1.00e-05, dropout = 5.00e-01\n",
      "============================================================\n",
      "[LSTM] Training model\n",
      "[LSTM] n_train=1408  #epochs=5  batch size=64\n",
      "[LSTM] Epoch 1 (16.86s)\tAverage loss=0.695601\tDev F1=25.70\n",
      "[LSTM] Epoch 5 (72.47s)\tAverage loss=0.689475\tDev F1=22.89\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (72.79s)\n",
      "[LSTM] Loaded model <LSTM>\n",
      "[LSTM] F-1 Score: 0.22891566265060243\n",
      "[LSTM] Loaded model <LSTM_3>\n"
     ]
    }
   ],
   "source": [
    "from dm_utils import LSTM\n",
    "from snorkel.learning import RandomSearch\n",
    "\n",
    "param_ranges = {\n",
    "    'lr' : [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'dropout' : [0.0, 0.5]\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'n_epochs' : 5,\n",
    "    'rebalance' : 0.5,\n",
    "    'print_freq' : 25,\n",
    "    'max_sentence_length': 100,\n",
    "    'dim': 50,\n",
    "}\n",
    "\n",
    "# We now add a session and probabilistic labels, as well as pass in the candidates\n",
    "# instead of the label matrix\n",
    "searcher = RandomSearch(LSTM, param_ranges, train_cands, Y_train=train_marginals, n=5,\n",
    "    model_hyperparams=model_hyperparams)\n",
    "\n",
    "# We now pass in the development candidates and the gold development labels\n",
    "lstm, run_stats = searcher.fit(dev_cands, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting discriminative model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n",
      "Prec: 0.800, Recall: 0.590, F1 Score: 0.679\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.59\n",
      "Neg. class accuracy: 0.931\n",
      "Precision            0.8\n",
      "Recall               0.59\n",
      "F1                   0.679\n",
      "----------------------------------------\n",
      "TP: 72 | FP: 18 | TN: 243 | FN: 50\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting and plotting discriminative model marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_cands = test_cands\n",
    "L_eval = L_gold_test\n",
    "eval_marginals = lstm.marginals(eval_cands)\n",
    "# Plotting eval marginals\n",
    "plt.hist(eval_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating extractions from discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gm_utils import create_extractions_dict\n",
    "\n",
    "# Enter googlemaps api key to get geocodes, leave blank to just use extracted locations\n",
    "geocode_key = None\n",
    "# geocode_key = 'AIzaSyBlLyOaasYMgMxFGUh2jJyxIG0_pZFF_jM'\n",
    "\n",
    "doc_extractions = create_extractions_dict(session, L_eval, eval_marginals, extractions=[extraction_type],\n",
    "                                          dummy=False, geocode_key=geocode_key)\n",
    "\n",
    "# Uncomment to inspecting extractions dict to check format\n",
    "#doc_extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving extractions to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Setting filename\n",
    "out_filename = \"loc_ext_test_discriminative.jsonl\"\n",
    "\n",
    "# Saving file to jsonl in extractions format\n",
    "with open(out_filename, 'w') as outfile:\n",
    "    for k,v in doc_extractions.items():\n",
    "        v['url'] = k\n",
    "        print(json.dumps(v), file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 383 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, eval_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <lstm>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(model_name='lstm',save_dir='checkpoints',verbose=True,global_step=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
