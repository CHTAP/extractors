{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is ensure that modules are auto-reloaded at runtime to allow for development in other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the Snorkel database location and start and connect to it.  By default, we use a PosgreSQL database backend, which can be created using `createdb DB_NAME` once psql is installed.  Note that Snorkel does *not* currently support parallel database processing with a SQLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://jdunnmon:123@localhost:5432'\n",
    "\n",
    "#postgres_db_name = 'es_locs_small'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "#For local PostgreSQL\n",
    "#os.environ['SNORKELDB'] = 'postgres:///es_locs_small'\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('..')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"es_locs_small.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Setting parallelism\n",
    "parallelism = 32\n",
    "\n",
    "# Setting random seed\n",
    "seed = 1701\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create candidate subclass and loading marginals for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import create_candidate_class\n",
    "from snorkel.annotations import load_marginals\n",
    "\n",
    "# Setting extraction type -- should be a subfield in your data source extractions field!\n",
    "extraction_type = 'location'\n",
    "\n",
    "# Creating candidate class\n",
    "candidate_class, candidate_class_name  = create_candidate_class(extraction_type)\n",
    "\n",
    "# Loading marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting train, dev, and test candidates and gold labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "# Getting candidates\n",
    "train_cands = session.query(candidate_class).filter(candidate_class.split == 0).order_by(candidate_class.id).all()\n",
    "dev_cands   = session.query(candidate_class).filter(candidate_class.split == 1).order_by(candidate_class.id).all()\n",
    "test_cands  = session.query(candidate_class).filter(candidate_class.split == 2).order_by(candidate_class.id).all()\n",
    "\n",
    "# Getting gold labels\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and discriminative model using hyperparameter search using PyTorch LSTM end model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=7202  #epochs=2  batch size=64\n",
      "[LSTM] Epoch 1 (13.18s)\tAverage loss=0.497391\tDev F1=20.41\n",
      "[LSTM] Epoch 2 (26.87s)\tAverage loss=0.445532\tDev F1=21.28\n",
      "[LSTM] Training done (26.92s)\n"
     ]
    }
   ],
   "source": [
    "from dm_utils import LSTM\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        50,\n",
    "    'n_epochs':   2,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1,\n",
    "    'max_sentence_length': 100\n",
    "}\n",
    "\n",
    "# Defining end model\n",
    "# TODO: check for cuda and use GPU\n",
    "lstm = LSTM(n_threads=parallelism)\n",
    "\n",
    "# Training end model\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting discriminative model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.205, Recall: 1.000, F1 Score: 0.340\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.132\n",
      "Precision            0.205\n",
      "Recall               1.0\n",
      "F1                   0.34\n",
      "----------------------------------------\n",
      "TP: 17 | FP: 66 | TN: 10 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting and plotting discriminative model marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_cands = test_cands\n",
    "eval_marginals = lstm.marginals(eval_cands)\n",
    "# Plotting eval marginals\n",
    "plt.hist(eval_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating extractions from discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gm_utils import create_extractions_dict\n",
    "doc_extractions = create_extractions_dict(session, eval_cands, eval_marginals, extractions=[extraction_type], dummy=True)\n",
    "\n",
    "# Uncomment to inspecting extractions dict to check format\n",
    "#doc_extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving extractions to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Setting filename\n",
    "out_filename = \"loc_ext_test_discriminative.jsonl\"\n",
    "\n",
    "# Saving file to jsonl in extractions format\n",
    "with open(out_filename, 'w') as outfile:\n",
    "    for k,v in doc_extractions.items():\n",
    "        v['url'] = k\n",
    "        print(json.dumps(v), file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving discriminative model marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 93 marginals\n"
     ]
    }
   ],
   "source": [
    "lstm.save_marginals(session, eval_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
