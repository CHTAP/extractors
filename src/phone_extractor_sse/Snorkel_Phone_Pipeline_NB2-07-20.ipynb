{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Write Labeling Functions and Train Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is ensure that modules are auto-reloaded at runtime to allow for development in other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the Snorkel database location and start and connect to it.  By default, we use a PosgreSQL database backend, which can be created using `createdb DB_NAME` once psql is installed.  Note that Snorkel does *not* currently support parallel database processing with a SQLite backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Snorkel DB location\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#For PostgreSQL\n",
    "postgres_location = 'postgresql://saeideh:123@localhost:5432'\n",
    "\n",
    "postgres_db_name = 'phone_sse_ver1'\n",
    "os.environ['SNORKELDB'] = os.path.join(postgres_location,postgres_db_name)\n",
    "\n",
    "# Adding path above for utils\n",
    "sys.path.append('..')\n",
    "\n",
    "# For SQLite\n",
    "#db_location = '.'\n",
    "#db_name = \"es_locs_small.db\"\n",
    "#os.environ['SNORKELDB'] = '{0}:///{1}/{2}'.format(\"sqlite\", db_location, db_name)\n",
    "\n",
    "# Start Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Setting parallelism\n",
    "parallelism = 32\n",
    "\n",
    "# Setting random seed\n",
    "seed = 1701\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create candidate subclass and get dev set candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Candidates: 204\n"
     ]
    }
   ],
   "source": [
    "from dataset_utils import create_candidate_class\n",
    "\n",
    "# Setting extraction type -- should be a subfield in your data source extractions field!\n",
    "extraction_type = 'phone'\n",
    "\n",
    "# Creating candidate class\n",
    "#candidate_class, candidate_class_name  = create_candidate_class(extraction_type)\n",
    "from snorkel.models import Candidate, candidate_subclass\n",
    "\n",
    "# Designing candidate subclasses\n",
    "PhoneExtraction = candidate_subclass('Phone', ['phone'])\n",
    "\n",
    "# Getting dev set and printing length\n",
    "cands_dev = session.query(PhoneExtraction.split).filter(PhoneExtraction.split == 1).order_by(PhoneExtraction.id).all()\n",
    "print(f'Dev Candidates: {len(cands_dev)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b3314e2496487093492352fbd0bf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SentenceNgramViewer(cids=[[[95]], [[19]], [[150, 154, 155, 157, 160]], [[100]], [[12]], [[87, 90, 92, 101, 103…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# load our list of training & development candidates\n",
    "train_cands = session.query(Candidate).filter(Candidate.split == 0).all()\n",
    "dev_cands   = session.query(Candidate).filter(Candidate.split == 1).all()\n",
    "\n",
    "SentenceNgramViewer(dev_cands[0:200], session, n_per_page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Labeling Functions (LFs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#from fonduer.lf_helpers import get_left_ngrams, get_right_ngrams, get_between_ngrams\n",
    "from snorkel.lf_helpers import get_tagged_text\n",
    "# from lib.init import *\n",
    "# from lib.scoring import *\n",
    "# from lib.lf_factories import *\n",
    "\n",
    "from snorkel.lf_helpers import test_LF\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text)\n",
    "from gm_utils import *\n",
    "from snorkel_utils_phone import phone_eval\n",
    "\n",
    "call_term=[\"text\",\"call\", \"celular\",\"tell\",\"blocked\",\"ask\",\n",
    "          'blocked', 'texts', 'emails', 'txt', 'texting', 'calltext', 'serious', 'msg', 'txts', \n",
    "           'inquires', 'respond', 'messaging', 'onlyi', 'disrespect', 'responding', 'inquiry',\n",
    "           'inappropriate', \n",
    "           'terminated', 'inquirers', 'ignored', 'schedule',\n",
    "           'thank', 'replies', 'dial', 'explict', 'preference', 'answered', 'preferred', 'restricted','phone']\n",
    "price_term =[\"minutes\",\"price\",\"hr\",\"hour\",\"min\",\"/hr\",\"minutes$\",\"mins\",'hhr',\n",
    "             'roses', 'hlf', 'fh', 'hh',\n",
    "             'hour', '$hour', 'donation', '$hh', 'reg', 'qk', 'min$'\n",
    "             , 'prices', 'hourly', 'qh', '$h', 'nonnegotiable', 'half', 'varies', 'stays',\"cash\"]\n",
    "weight_height =[\"weight\",\"thin\",\"lb\",\"body\",\"kgs\",\"kg\",'pds', 'weigh', \"'ft\", 'ftin', 'ibs',\n",
    "                'measurement', 'stats', 'chest', \"'lbs\", 'lbsi', 'pound', 'pert', \"c's\", 'bls',\n",
    "                'cups', \"c'\", 'stand', 'standing', 'measurements', 'lbsc', 'kgs', 'medium']\n",
    "\n",
    "area_code_lst = [\"307\",\"262\", \"414\", \"534\",\"608\",\"715\",\"920\",\"304\",\"681\",\"202\",\"206\",\"253\",\n",
    "                 \"360\",\"425\",\"509\",\"276\",\"434\",\"540\",\"571\",\"703\",\"757\",\"804\",\"340\",\"802\", \"385\", \"435\", \"801\", \"210\", \"214\",\"254\", \"281\", \"325\", \"346\",\n",
    "                 \"361\", \"409\", \"430\", \"432\", \"469\", \"512\", \"682\", \"713\", \"737\", \"806\", \"817\", \"830\", \"832\", \"903\", \"915\", \"936\", \"940\",\n",
    "                 \"956\", \"972\", \"979\", \"423\", \"615\", \"629\", \"731\", \"865\", \"901\", \"931\",\"605\", \"803\", \"843\",\n",
    "                 \"854\", \"864\",\"401\", \"787\", \"939\", \"215\", \"267\", \"272\", \"412\", \"484\", \"570\", \"610\", \"717\", \"724\", \"814\", \"878\", \"215\", \"267\",\n",
    "                 \"272\", \"412\", \"484\", \"570\", \"610\", \"717\", \"724\", \"814\", \"878\", \"405\", \"539\", \"580\", \"918\", \"216\", \"220\", \"234\", \"330\", \"380\", \"419\",\n",
    "                 \"440\", \"513\", \"567\", \"614\", \"740\", \"937\", \"701\", \"670\", \"252\", \"336\", \"704\", \"743\", \"828\", \"910\", \"919\", \"980\", \"984\", \n",
    "\"212\", \"315\", \"332\", \"347\", \"516\", \"518\", \"585\", \"607\", \"631\", \"646\", \"680\", \"716\", \"718\", \"845\", \"914\", \"917\", \"929\", \"934\", \"505\", \"575\", \"201\",\n",
    "                 \"551\", \"609\", \"732\", \"848\", \"856\", \"862\", \"908\", \"973\", \n",
    "\"603\", \"702\", \"725\", \"775\", \"308\", \"402\", \"531\", \"406\", \"314\", \"417\", \"573\", \"636\",\"660\", \"816\", \"228\", \"601\", \"662\", \"769\", \"218\", \"320\", \"507\",\n",
    "                 \"612\", \"651\", \"763\", \"952\", \"231\", \"248\", \"269\", \"313\", \"517\", \"586\",\n",
    "                 \"616\", \"734\", \"810\", \"906\", \"947\", \"989\", \"339\", \"351\", \"413\", \"508\", \"617\"\n",
    "                 , \"774\", \"781\", \"857\", \"978\", \"240\", \"301\", \"410\", \"443\", \"667\", \"207\",\n",
    "                 \"225\", \"318\", \"337\", \"504\", \"985\", \"270\", \"364\", \"502\", \"606\", \"859\", \"316\",\n",
    "                 \"620\", \"785\", \"913\", \"319\", \"515\", \"563\", \"641\", \"712\", \"219\", \"260\",\n",
    "                 \"317\", \"463\", \"574\", \"765\", \"812\", \"930\", \"217\", \"224\", \"309\", \"312\", \"331\",\n",
    "                 \"618\", \"630\", \"708\", \"773\", \"779\", \"815\", \"847\", \"872\", \"208\", \"808\",\n",
    "                 \"671\", \"229\", \"404\", \"470\", \"478\", \"678\", \"706\", \"762\", \"770\", \"912\", \"239\"\n",
    "                 , \"305\", \"321\", \"352\", \"386\", \"407\", \"561\", \"727\", \"754\", \"772\", \"786\", \"813\",\n",
    "                 \"850\", \"863\", \"904\", \"941\", \"954\", \"203\", \"475\", \"860\", \"959\", \"302\", \"303\",\n",
    "                 \"719\", \"720\", \"970\", \"209\", \"213\", \"310\", \"323\", \"408\", \"415\", \"424\", \"442\", \n",
    "                 \"510\", \"530\", \"559\", \"562\", \"619\", \"626\", \"628\", \"650\", \"657\", \"661\", \"669\",\n",
    "                 \"707\", \"714\", \"747\", \"760\", \"805\", \"818\", \"831\", \"858\", \"909\",\n",
    "                 \"916\", \"925\", \"949\", \"951\", \"479\", \"501\", \"870\", \"480\", \"520\", \"602\", \"623\",\n",
    "                 \"928\", \"684\", \"907\", \"205\", \"251\", \"256\", \"334\", \"938\"]\n",
    "\n",
    "def LF_phone_terms(c):\n",
    "    split_txt = c[0].get_parent().text.lower().split()\n",
    "    \n",
    "    if len(list(set(call_term) & set(split_txt)))>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    #return 1 if len(call_term.intersection(c[0].get_parent().text.lower())) > 0 else 0\n",
    "\n",
    "def LF_phone_term_right_left(c):\n",
    "    left_token = get_left_tokens(c[0], window=10)\n",
    "    right_token = get_right_tokens(c[0], window=10)\n",
    "    if len(list(set(call_term) & set(left_token)))>0:\n",
    "        return 1\n",
    "    elif len(list(set(call_term) & set(right_token)))>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_no_call_term(c):\n",
    "    split_txt = c[0].get_parent().text.lower().split()\n",
    "    \n",
    "    if len(list(set(call_term) & set(split_txt)))>0 and  np.random.rand() > 0.75:\n",
    "        return 1 \n",
    "    else:\n",
    "        0\n",
    "    \n",
    "def LF_price_term(c):\n",
    "    #return -1 if len(price_term.intersection(c[0].get_parent().text.lower())) > 0 else 0\n",
    "    split_txt = c[0].get_parent().text.lower().split()\n",
    "    \n",
    "    if len(list(set(price_term) & set(split_txt)))>0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def lF_price_term_right_left(c):\n",
    "#     if len(price_term.intersection(get_left_tokens(c[0], window=10))) > 0:\n",
    "#         return -1\n",
    "#     elif len(price_term.intersection(get_right_tokens(c[0], window=10))) > 0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "    left_token = get_left_tokens(c[0], window=10)\n",
    "    right_token = get_right_tokens(c[0], window=10)\n",
    "    if len(list(set(price_term) & set(left_token)))>0:\n",
    "        return -1\n",
    "    elif len(list(set(price_term) & set(right_token)))>0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_body_term(c):\n",
    "    #return -1 if len(weight_height.intersection(c[0].get_parent().text.lower())) > 0 else 0\n",
    "    split_txt = c[0].get_parent().text.lower().split()\n",
    "    \n",
    "    if len(list(set(weight_height) & set(split_txt)))>0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_body_term_right_left(c):\n",
    "#     if len(weight_height.intersection(get_left_tokens(c[0], window=10))) > 0:\n",
    "#         return -1\n",
    "#     elif len(weight_height.intersection(get_right_tokens(c[0], window=10))) > 0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return   \n",
    "    left_token = get_left_tokens(c[0], window=10)\n",
    "    right_token = get_right_tokens(c[0], window=10)\n",
    "    if len(list(set(weight_height) & set(left_token)))>0:\n",
    "        return -1\n",
    "    elif len(list(set(weight_height) & set(right_token)))>0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# def LF_phone_terms(c):\n",
    "#     split_txt = c[0].get_parent().text.lower().split()\n",
    "    \n",
    "#     if len(list(set(call_term) & set(split_txt)))>0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "# # c.phone.get_span().lower().split()   \n",
    "#     #return 1 if len(call_term.intersection(c[0].get_parent().text.lower())) > 0 else 0\n",
    "\n",
    "# def LF_phone_term_right_lef(c):\n",
    "#     left_token = get_left_tokens(c[0], window=10)\n",
    "#     right_token = get_right_tokens(c[0], window=10)\n",
    "#     if len(list(set(call_term) & set(left_token)))>0:\n",
    "#         return 1\n",
    "#     elif len(list(set(call_term) & set(right_token)))>0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# def LF_no_call_term(c):\n",
    "#     split_txt = c[0].get_parent().text.lower().split()\n",
    "    \n",
    "#     if len(list(set(call_term) & set(split_txt)))>0 and  np.random.rand() > 0.75:\n",
    "#         return 1 \n",
    "#     else:\n",
    "#         0\n",
    "    \n",
    "# def LF_price_term(c):\n",
    "#     #return -1 if len(price_term.intersection(c[0].get_parent().text.lower())) > 0 else 0\n",
    "#     split_txt =c[0].get_parent().text.lower().split() #c.phone.get_span().lower().split().split()\n",
    "    \n",
    "#     if len(list(set(price_term) & set(split_txt)))>0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# def lF_price_term_right_left(c):\n",
    "# #     if len(price_term.intersection(get_left_tokens(c[0], window=10))) > 0:\n",
    "# #         return -1\n",
    "# #     elif len(price_term.intersection(get_right_tokens(c[0], window=10))) > 0:\n",
    "# #         return -1\n",
    "# #     else:\n",
    "# #         return 0\n",
    "#     left_token = get_left_tokens(c[0], window=10)\n",
    "#     right_token = get_right_tokens(c[0], window=10)\n",
    "#     if len(list(set(price_term) & set(left_token)))>0:\n",
    "#         return -1\n",
    "#     elif len(list(set(price_term) & set(right_token)))>0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# def LF_body_term(c):\n",
    "#     #return -1 if len(weight_height.intersection(c[0].get_parent().text.lower())) > 0 else 0\n",
    "#     split_txt = c[0].get_parent().text.lower().split()#c.phone.get_span().lower().split()\n",
    "    \n",
    "#     if len(list(set(weight_height) & set(split_txt)))>0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# def LF_body_term_right_left(c):\n",
    "# #     if len(weight_height.intersection(get_left_tokens(c[0], window=10))) > 0:\n",
    "# #         return -1\n",
    "# #     elif len(weight_height.intersection(get_right_tokens(c[0], window=10))) > 0:\n",
    "# #         return -1\n",
    "# #     else:\n",
    "# #         return   \n",
    "#     left_token = get_left_tokens(c[0], window=10)\n",
    "#     right_token = get_right_tokens(c[0], window=10)\n",
    "#     if len(list(set(weight_height) & set(left_token)))>0:\n",
    "#         return -1\n",
    "#     elif len(list(set(weight_height) & set(right_token)))>0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# def LF_check_area_code(c):\n",
    "#     results = {}\n",
    "#     cand = phone_eval(c[0].get_span())\n",
    "    \n",
    "#     #print(cand)\n",
    "#     if len(cand)==14:\n",
    "#         #results = {}\n",
    "#         results[cand[1:4]] = cand\n",
    "    \n",
    "#     result = -1\n",
    "#     for code in area_code_lst:\n",
    "      \n",
    "#         if code == cand[1:4]:\n",
    "#             result = +1\n",
    "#             #print(results[code])\n",
    "#             break\n",
    "        \n",
    "#     return result\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFs = [LF_phone_terms,LF_phone_term_right_left, \n",
    "    LF_no_call_term, LF_price_term, lF_price_term_right_left,\n",
    "    LF_body_term, LF_body_term_right_left]#,LF_check_area_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 276 ms, sys: 712 ms, total: 988 ms\n",
      "Wall time: 4.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/local/0/saeideh/snorkel/snorkel/snorkel/annotations.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ac = (tp+tn) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_phone_terms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.377451</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_phone_term_right_left</th>\n",
       "      <td>1</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_no_call_term</th>\n",
       "      <td>2</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_price_term</th>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lF_price_term_right_left</th>\n",
       "      <td>4</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_body_term</th>\n",
       "      <td>5</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_body_term_right_left</th>\n",
       "      <td>6</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_phone_terms            0  0.377451  0.352941   0.102941   0   0   0   0   \n",
       "LF_phone_term_right_left  1  0.367647  0.323529   0.083333   0   0   0   0   \n",
       "LF_no_call_term           2  0.102941  0.102941   0.019608   0   0   0   0   \n",
       "LF_price_term             3  0.166667  0.132353   0.068627   0   0   0   0   \n",
       "lF_price_term_right_left  4  0.117647  0.107843   0.044118   0   0   0   0   \n",
       "LF_body_term              5  0.117647  0.053922   0.039216   0   0   0   0   \n",
       "LF_body_term_right_left   6  0.014706  0.014706   0.000000   0   0   0   0   \n",
       "\n",
       "                          Empirical Acc.  \n",
       "LF_phone_terms                       NaN  \n",
       "LF_phone_term_right_left             NaN  \n",
       "LF_no_call_term                      NaN  \n",
       "LF_price_term                        NaN  \n",
       "lF_price_term_right_left             NaN  \n",
       "LF_body_term                         NaN  \n",
       "LF_body_term_right_left              NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  snorkel.annotations import LabelAnnotator\n",
    "import numpy as np\n",
    "labeler = LabelAnnotator(lfs=LFs)\n",
    "\n",
    "%time L_dev = labeler.apply(split=1, parallelism=parallelism)\n",
    "L_dev.lf_stats(session, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lf_geograpy_entity_neg(c):\n",
    "#     txt = c.location.get_span().lower()\n",
    "#     sent = c.get_parent().text\n",
    "#     e = extraction.Extractor(text=sent)\n",
    "#     e.find_entities()\n",
    "#     places = [p.lower() for p in e.places]\n",
    "#     if txt not in places:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# def lf_geograpy_entity_pos(c):\n",
    "#     txt = c.location.get_span().lower()\n",
    "#     sent = c.get_parent().text\n",
    "#     e = extraction.Extractor(text=sent)\n",
    "#     e.find_entities()\n",
    "#     places = [p.lower() for p in e.places]\n",
    "#     if txt not in places:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "    \n",
    "# def lf_geograpy_country(c):\n",
    "#     txt = c.location.get_span().lower()\n",
    "#     sent = c.get_parent().text\n",
    "#     places = geograpy.get_place_context(text=sent)\n",
    "#     if places.countries:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# def lf_call(c):\n",
    "#     call_words = ['call']\n",
    "#     return -1 if overlap(\n",
    "#       call_words, \n",
    "#       get_left_ngrams(c, window=1)) else 0\n",
    "\n",
    "# def lf_many_locations(c):\n",
    "#     txt = c.location.get_span().lower()\n",
    "#     sent = c.get_parent().text\n",
    "#     e = extraction.Extractor(text=sent)\n",
    "#     e.find_entities()\n",
    "#     thresh = 3\n",
    "#     return -1 if len(e.places)>thresh else 0\n",
    "\n",
    "\n",
    "# def lf_is_country(c):\n",
    "#     txt = c.location.get_span().lower()\n",
    "#     if lookup_country_name(txt).lower() != 'no country': return 1 \n",
    "#     if lookup_country_alpha2(txt).lower() != 'no country': return 1 \n",
    "#     if lookup_country_alpha3(txt).lower() != 'no country': \n",
    "#         return 1 \n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "    \n",
    "# def lf_is_state(c):\n",
    "#     txt = c.location.get_span().lower()\n",
    "#     if lookup_state_name(txt).lower() != 'no state' : return 1\n",
    "#     if lookup_state_abbr(txt).lower() != 'no state':\n",
    "#         return 1 \n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# def lf_following_words(c):\n",
    "#     following_words = ['area', 'escort', 'province']\n",
    "#     return 1 if overlap(\n",
    "#       following_words, \n",
    "#       get_left_ngrams(c, window=3)) else 0\n",
    "\n",
    "# def lf_preceding_words(c):\n",
    "#     preceding_words = ['escort','province','area']\n",
    "#     return 1 if overlap(\n",
    "#       preceding_words, \n",
    "#       get_right_ngrams(c, window=3)) else 0\n",
    "\n",
    "# def lf_escort(c):\n",
    "#     words = ['escort']\n",
    "#     return 1 if overlap(\n",
    "#       words, \n",
    "#       get_right_ngrams(c, window=2)) or overlap(\n",
    "#       words, \n",
    "#       get_left_ngrams(c, window=10))else 0\n",
    "\n",
    "# def lf_from(c):\n",
    "#     words = ['based']\n",
    "#     return 1 if overlap(\n",
    "#       words, \n",
    "#       get_right_ngrams(c, window=5)) or overlap(\n",
    "#       words, \n",
    "#       get_left_ngrams(c, window=5))else 0\n",
    "\n",
    "# def lf_area(c):\n",
    "#     words = ['area']\n",
    "#     return 1 if overlap(\n",
    "#       words, \n",
    "#       get_right_ngrams(c, window=5)) or overlap(\n",
    "#       words, \n",
    "#       get_left_ngrams(c, window=5))else 0\n",
    "\n",
    "\n",
    "# def lf_long_context(c):\n",
    "#     sent = c.get_parent().text.split()\n",
    "#     return -1 if len(sent)>10 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating list of LFs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFs = [\n",
    "#     lf_geograpy_entity_pos,\n",
    "#     lf_geograpy_entity_neg,\n",
    "#     lf_call,\n",
    "#     lf_many_locations,\n",
    "#     lf_following_words,\n",
    "#     lf_from,\n",
    "#     lf_geograpy_country,\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading gold dev set labels from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating labeling functions on dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from  snorkel.annotations import LabelAnnotator\n",
    "# import numpy as np\n",
    "# labeler = LabelAnnotator(lfs=LFs)\n",
    "\n",
    "# %time L_dev = labeler.apply(split=1, parallelism=parallelism)\n",
    "# L_dev.lf_stats(session, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating viewer to assist in LF development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# # Can insert function here to select candidates based on arbitary criteria\n",
    "\n",
    "# #Creating viewer for dev candidates\n",
    "# SentenceNgramViewer(cands_dev[0:20], session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once LFs are performing well, apply to entire database.  Applying to unlabeled data can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from  snorkel.annotations import LabelAnnotator\n",
    "# import numpy as np\n",
    "# labeler = LabelAnnotator(lfs=LFs)\n",
    "\n",
    "# %time L_train = labeler.apply(split=0, parallelism=parallelism)\n",
    "# %time L_test = labeler.apply(split=2, parallelism=parallelism)\n",
    "\n",
    "# can also load with:\n",
    "# %time L_train = labeler.load_matrix(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snorkel.learning import GenerativeModel\n",
    "# from snorkel.learning import RandomSearch\n",
    "\n",
    "# # Setting parameter ranges for search\n",
    "# param_ranges = {\n",
    "#     'step_size' : [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "#     'decay' : [1.0, 0.95, 0.9],\n",
    "#     'epochs' : [20, 50, 100]\n",
    "# }\n",
    "\n",
    "# # Creating generative model\n",
    "# gen_model = GenerativeModel()\n",
    "\n",
    "# # Creating searcher over hyperparameters-- n is the number of models to train\n",
    "# searcher = RandomSearch(GenerativeModel, param_ranges, L_train, n=5)\n",
    "\n",
    "# # Searching model\n",
    "# %time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev, n_threads=parallelism)\n",
    "\n",
    "# # Printing results of model search\n",
    "# run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing learned LF accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis for generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting marginals, plotting training marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# L_eval = L_test\n",
    "# eval_marginals = gen_model.marginals(L_eval)\n",
    "# training_marginals = gen_model.marginals(L_train)\n",
    "\n",
    "# # Plotting training marignals\n",
    "# plt.hist(training_marginals, bins=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dictionary of extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gm_utils import create_extractions_dict\n",
    "# doc_extractions = create_extractions_dict(session, L_eval, eval_marginals, extractions=[extraction_type], dummy=True)\n",
    "\n",
    "# Uncomment to inspecting extractions dict to check format\n",
    "#doc_extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving extractions to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Setting filename\n",
    "# out_filename = \"loc_ext_test_generative.jsonl\"\n",
    "\n",
    "# # Saving file to jsonl in extractions format\n",
    "# with open(out_filename, 'w') as outfile:\n",
    "#     for k,v in doc_extractions.items():\n",
    "#         v['url'] = k\n",
    "#         print(json.dumps(v), file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving training marginals for use with discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snorkel.annotations import save_marginals\n",
    "# %time save_marginals(session, L_train, train_marginals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
